{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "In this notebook, I will demonstrate an algorithmic approach to fill in (nearly) every missing Cabin value in the Space Titanic dataset. Unlike probabilistic or guessing methods, this approach follows a structured order based on each passenger's Homeplanet and group (derived from their PassengerID).\n",
    "\n",
    "Cabins are filled sequentially based on their numbers. For instance, if a passenger is assigned to cabin A/05/P, a passenger in a subsequent group cannot be assigned to A/04/P. However, they could be assigned to A/01/S or B/01/P.\n",
    "\n",
    "By employing this method, we aim to achieve a more accurate and logical imputation of missing Cabin values, which will improve the performance of our predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Cabin and PassengerID Components and Assumptions\n",
    "\n",
    "The Cabin column in the dataset is structured in the format A/01/P, where:\n",
    "\n",
    "- **A**: Cabin deck, which can take values 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'\n",
    "- **01**: Cabin number, which can take values 0, 1, 2, ...\n",
    "- **P**: Cabin side, which can take values 'P' (Port) or 'S' (Starboard)\n",
    "\n",
    "The PassengerId column in the dataset is structured in the format 0201_01, where:\n",
    "- **0201**: Group, these codes correspond to other members of the same group\n",
    "- **01**: Group number, always starts at 1 and will cout how many members there are in a group\n",
    "\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "To facilitate our imputation approach, we make several key assumptions:\n",
    "\n",
    "1. **Group Members Share the Same Side**: If two passengers are in the same group, they are on the same side of the ship. (Appendix A.1)\n",
    "2. **Group Members Share the Same Home Planet**: If two passengers are in the same group, they originate from the same home planet. (Appendix A.2)\n",
    "3. **Shared Last Names Indicate Same Home Planet**: Passengers sharing a last name are from the same home planet. (Appendix A.3)\n",
    "4. **Children Have No Bills**: Passengers aged 12 or younger do not incur any bills. (Appendix A.4)\n",
    "5. **Cryosleep Implies No Bills**: Passengers who are in cryosleep do not incur any bills. (Appendix A.5)\n",
    "6. **Cabins Shared Within Groups**: Cabins can only be shared by members of the same group. (Appendix A.6)\n",
    "7. **Home Planets and Deck Restrictions**: Passengers' home planets restrict which decks they can be assigned to. (Appendix B)\n",
    "    - **Mars**: Decks 'D', 'E', or 'F'\n",
    "    - **Earth**: Decks 'E', 'F', or 'G'\n",
    "    - **Europa**: Decks 'A', 'B', 'C', 'D', 'E', or 'T'\n",
    "    - Passengers with no bills and group members on different decks have further restrictions:\n",
    "        - **Earth**: Restricted to deck 'G'\n",
    "        - **Europa**: Restricted to deck 'B'\n",
    "        - **Mars**: Restricted to decks 'E' and 'F'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maintain the order of passengers by group, we combine the training and test datasets. This combined dataframe will be used for the rest of the project, ensuring consistency in our imputation process.\n",
    "\n",
    "By combining the datasets, we have a more comprehensive view of all passengers, which will aid in the structured filling of missing Cabin values.\n",
    "\n",
    "Below is the code to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "  Transported    Set  \n",
       "0       False  Train  \n",
       "1        True  Train  \n",
       "2       False  Train  \n",
       "3       False  Train  \n",
       "4        True  Train  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd \n",
    "from collections import defaultdict # Slightly modified from a regular dictionary\n",
    "\n",
    "# Load the training and test data\n",
    "training_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Add a column to distinguish between the training and test sets\n",
    "training_data['Set'] = 'Train'\n",
    "test_data['Set'] = 'Test'\n",
    "\n",
    "# Combine the training and test datasets\n",
    "df = pd.concat([training_data, test_data])\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we perform several essential preprocessing steps to prepare our data for imputation and analysis. These steps include splitting relevant columns, sorting the dataframe, and handling missing values in a structured manner.\n",
    "\n",
    "First, let's verify the number of missing Cabin values in our combined dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our starting point, and we have identified that there are 299 missing Cabin values. Our next step will be to address these missing values systematically using the assumptions defined earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of missing values in the Cabin column\n",
    "df['Cabin'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split the unique PassengerId into Group and their number in the group, split the Cabin into deck, side, and number, and split their names into first and last name. This segmentation helps us leverage the information contained within these columns more effectively.\n",
    "\n",
    "Here is the code to achieve these splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Set</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "      <td>0001</td>\n",
       "      <td>01</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>Maham</td>\n",
       "      <td>Ofracculy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "      <td>0002</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Juanna</td>\n",
       "      <td>Vines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>01</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Altark</td>\n",
       "      <td>Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>02</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Solam</td>\n",
       "      <td>Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "      <td>0004</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Willy</td>\n",
       "      <td>Santantines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...               Name  Transported  \\\n",
       "0          0.0        0.0           0.0  ...    Maham Ofracculy        False   \n",
       "1        109.0        9.0          25.0  ...       Juanna Vines         True   \n",
       "2         43.0     3576.0           0.0  ...      Altark Susent        False   \n",
       "3          0.0     1283.0         371.0  ...       Solam Susent        False   \n",
       "4        303.0       70.0         151.0  ...  Willy Santantines         True   \n",
       "\n",
       "     Set Group GroupNumber CabinDeck CabinNumber CabinSide  FirstName  \\\n",
       "0  Train  0001          01         B           0         P      Maham   \n",
       "1  Train  0002          01         F           0         S     Juanna   \n",
       "2  Train  0003          01         A           0         S     Altark   \n",
       "3  Train  0003          02         A           0         S      Solam   \n",
       "4  Train  0004          01         F           1         S      Willy   \n",
       "\n",
       "      LastName  \n",
       "0    Ofracculy  \n",
       "1        Vines  \n",
       "2       Susent  \n",
       "3       Susent  \n",
       "4  Santantines  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to split columns into multiple components\n",
    "def column_splits(data_frame):\n",
    "    # Split PassengerId into Group and GroupNumber\n",
    "    data_frame[['Group', 'GroupNumber']] = data_frame['PassengerId'].str.split('_', expand=True)\n",
    "    \n",
    "    # Split Cabin into CabinDeck, CabinNumber, and CabinSide\n",
    "    data_frame[['CabinDeck', 'CabinNumber', 'CabinSide']] = data_frame['Cabin'].str.split(\"/\", expand=True)\n",
    "    data_frame['CabinNumber'] = data_frame['CabinNumber'].astype('Int64')\n",
    "    \n",
    "    # Split Name into FirstName and LastName\n",
    "    data_frame[['FirstName', 'LastName']] = data_frame['Name'].str.split(\" \", expand=True)\n",
    "\n",
    "    return data_frame\n",
    "\n",
    "# Apply the function to the combined dataframe\n",
    "df = column_splits(df)\n",
    "\n",
    "# Sort the dataframe by Group and GroupNumber\n",
    "df = df.sort_values(by=['Group', 'GroupNumber'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the modified dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total bills are composed of the summation of each passengers roomservice, foodcourt, shoppingmall, spa and vrdeck payments.\n",
    "We can impute bills to be equal to 0 if someone is under 13 and/or they are in cryosleep (Appendix A.4,A.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total bills for each passenger\n",
    "df['Bills'] = df['RoomService'] + df['FoodCourt'] + df['ShoppingMall'] + df['Spa'] + df['VRDeck']\n",
    "\n",
    "# Impute bills to be zero for passengers under 13 or in cryosleep\n",
    "df.loc[df['Age'] < 13, 'Bills'] = 0\n",
    "df.loc[df['CryoSleep'] == True, 'Bills'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add a useful column to our dataframe: GroupSize, which indicates the number of passengers in each group. This helps us understand group dynamics and may assist in the imputation process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>Set</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Bills</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0001</td>\n",
       "      <td>01</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>Maham</td>\n",
       "      <td>Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0002</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Juanna</td>\n",
       "      <td>Vines</td>\n",
       "      <td>736.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>01</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Altark</td>\n",
       "      <td>Susent</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>02</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Solam</td>\n",
       "      <td>Susent</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0004</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Willy</td>\n",
       "      <td>Santantines</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...    Set  Group GroupNumber  \\\n",
       "0          0.0        0.0           0.0  ...  Train   0001          01   \n",
       "1        109.0        9.0          25.0  ...  Train   0002          01   \n",
       "2         43.0     3576.0           0.0  ...  Train   0003          01   \n",
       "3          0.0     1283.0         371.0  ...  Train   0003          02   \n",
       "4        303.0       70.0         151.0  ...  Train   0004          01   \n",
       "\n",
       "  CabinDeck CabinNumber CabinSide FirstName     LastName    Bills GroupSize  \n",
       "0         B           0         P     Maham    Ofracculy      0.0         1  \n",
       "1         F           0         S    Juanna        Vines    736.0         1  \n",
       "2         A           0         S    Altark       Susent  10383.0         2  \n",
       "3         A           0         S     Solam       Susent   5176.0         2  \n",
       "4         F           1         S     Willy  Santantines   1091.0         1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to add a GroupSize column\n",
    "def add_group_size_column(dataframe):\n",
    "    dataframe['GroupSize'] = dataframe.groupby('Group')['Group'].transform('count')\n",
    "    return dataframe\n",
    "\n",
    "# Apply the function to the combined dataframe\n",
    "df = add_group_size_column(df)\n",
    "\n",
    "# Display the first few rows of the dataframe with the new GroupSize column\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further enhance our dataset, we define a function to impute missing values based on shared features. For instance, rows with missing values for HomePlanet can be imputed if they share a group with someone whose HomePlanet is known or share a last name with someone whose HomePlanet is known (Appendix A.2, A.3):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>Set</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Bills</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0001</td>\n",
       "      <td>01</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>Maham</td>\n",
       "      <td>Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0002</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Juanna</td>\n",
       "      <td>Vines</td>\n",
       "      <td>736.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>01</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Altark</td>\n",
       "      <td>Susent</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>02</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Solam</td>\n",
       "      <td>Susent</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0004</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Willy</td>\n",
       "      <td>Santantines</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...    Set  Group GroupNumber  \\\n",
       "0          0.0        0.0           0.0  ...  Train   0001          01   \n",
       "1        109.0        9.0          25.0  ...  Train   0002          01   \n",
       "2         43.0     3576.0           0.0  ...  Train   0003          01   \n",
       "3          0.0     1283.0         371.0  ...  Train   0003          02   \n",
       "4        303.0       70.0         151.0  ...  Train   0004          01   \n",
       "\n",
       "  CabinDeck CabinNumber CabinSide FirstName     LastName    Bills GroupSize  \n",
       "0         B           0         P     Maham    Ofracculy      0.0         1  \n",
       "1         F           0         S    Juanna        Vines    736.0         1  \n",
       "2         A           0         S    Altark       Susent  10383.0         2  \n",
       "3         A           0         S     Solam       Susent   5176.0         2  \n",
       "4         F           1         S     Willy  Santantines   1091.0         1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to impute attributes based on shared features\n",
    "def impute_attribute_by_shared_features(dataframe, attribute, shared_feature):\n",
    "    # Iterate through rows with missing values for the specified attribute\n",
    "    for index, row in dataframe[dataframe[attribute].isna()].iterrows():\n",
    "        # Find rows that share the specified feature and have known values for the attribute\n",
    "        rows_with_shared_features = dataframe[dataframe[shared_feature] == row[shared_feature]].dropna(subset=[attribute])\n",
    "        \n",
    "        # Impute the attribute if there are rows with shared features and known values\n",
    "        if not rows_with_shared_features.empty:\n",
    "            dataframe.loc[index, attribute] = rows_with_shared_features[attribute].iloc[0]\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "# Impute missing HomePlanet values based on shared group or last name\n",
    "df = impute_attribute_by_shared_features(df, 'HomePlanet', 'Group')\n",
    "df = impute_attribute_by_shared_features(df, 'HomePlanet', 'LastName')\n",
    "\n",
    "# Display the first few rows of the dataframe with imputed HomePlanet values\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Potential Cabin Decks and Sides\n",
    "\n",
    "For passengers with missing Cabin values, we can limit their options by excluding certain cabin decks or sides based on their attributes. This step is crucial for our structured imputation process. Specifically:\n",
    "\n",
    "1. **Home Planet Deck Restrictions**: Each home planet restricts passengers to certain decks. Additionally, if a passenger has no bills and their group members are on multiple decks, their deck is further restricted based on their home planet (Appendix B).\n",
    "2. **Group Cabin Side Consistency**: Every group is restricted to a single cabin side, even if they are split into multiple cabins (Appendix A.1).\n",
    "\n",
    "We define functions to add columns for potential decks and sides for passengers with missing Cabin values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to add a column for potential decks based on home planet and other conditions\n",
    "def add_potential_decks_column(dataframe):\n",
    "    # Define potential decks for each home planet\n",
    "    potential_decks_by_homeplanet = {\n",
    "        'Earth': ['E', 'F', 'G'],\n",
    "        'Europa': ['A', 'B', 'C', 'D', 'E', 'T'],\n",
    "        'Mars': ['D', 'E', 'F']\n",
    "    }\n",
    "\n",
    "    # Define restricted decks for passengers with no bills\n",
    "    potential_decks_by_homeplanet_no_bills = {\n",
    "        'Earth': ['G'],\n",
    "        'Europa': ['B'],\n",
    "        'Mars': ['E', 'F']\n",
    "    }\n",
    "    \n",
    "    # Inner function to determine potential decks for each passenger\n",
    "    def func_potential_decks_apply(row):\n",
    "        # If the Cabin value is missing\n",
    "        if pd.isna(row.Cabin):\n",
    "            # If the passenger has no bills, a known HomePlanet, and is part of a group\n",
    "            if row.Bills == 0 and not pd.isna(row.HomePlanet) and row.GroupSize > 1:\n",
    "                # Get the decks of other group members\n",
    "                group_members = dataframe[(dataframe.Group == row.Group) & (dataframe.PassengerId != row.PassengerId)].CabinDeck\n",
    "                \n",
    "                # If group members are in multiple different decks, restrict to specific decks for no bills\n",
    "                if group_members.dropna().nunique() > 1:\n",
    "                    return potential_decks_by_homeplanet_no_bills[row.HomePlanet]\n",
    "                \n",
    "                # If no group members have a known deck, return a combination of specific decks for no bills and known decks\n",
    "                elif not group_members.isna().any():\n",
    "                    return list(set(potential_decks_by_homeplanet_no_bills[row.HomePlanet] + list(group_members.dropna().unique())))\n",
    "                \n",
    "                # If group members are in one known deck, check if it matches the restricted decks\n",
    "                if group_members.nunique() == 1:\n",
    "                    if group_members.iloc[0] in potential_decks_by_homeplanet_no_bills[row.HomePlanet]:\n",
    "                        return potential_decks_by_homeplanet_no_bills[row.HomePlanet]\n",
    "            \n",
    "            # If the passenger has bills, return the standard decks for their HomePlanet\n",
    "            if not pd.isna(row.HomePlanet):\n",
    "                return potential_decks_by_homeplanet[row.HomePlanet]\n",
    "            \n",
    "            # If the HomePlanet is unknown, return all unique decks in the dataframe\n",
    "            else:\n",
    "                return list(dataframe.CabinDeck.dropna().unique())\n",
    "    \n",
    "    # Apply the inner function to each row in the dataframe\n",
    "    dataframe['PotentialDecks'] = dataframe.apply(func_potential_decks_apply, axis=1)\n",
    "    return dataframe\n",
    "\n",
    "# Define a function to add a column for potential sides based on group consistency\n",
    "def add_potential_sides_column(dataframe):\n",
    "    # Inner function to determine potential sides for each passenger\n",
    "    def func_potential_sides_apply(row):\n",
    "        # If the Cabin value is missing\n",
    "        if pd.isna(row.Cabin):\n",
    "            # Get the sides of other group members\n",
    "            group_sides = dataframe[dataframe.Group == row.Group].CabinSide.dropna()\n",
    "            \n",
    "            # If other group members have a known side, return that side\n",
    "            if group_sides.nunique() > 0:\n",
    "                return [group_sides.iloc[0]]\n",
    "            \n",
    "            # If no group members have a known side, return both possible sides\n",
    "            return ['P', 'S']\n",
    "        \n",
    "    # Apply the inner function to each row in the dataframe\n",
    "    dataframe['PotentialSides'] = dataframe.apply(func_potential_sides_apply, axis=1)\n",
    "    return dataframe\n",
    "\n",
    "# Apply the functions to add potential decks and sides columns\n",
    "df = add_potential_decks_column(df)\n",
    "df = add_potential_sides_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by Group and GroupNumber\n",
    "df = df.sort_values(by=['Group', 'GroupNumber'])\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding these columns, we can better manage the imputation of missing Cabin values by limiting the possible options based on the passenger's attributes and group dynamics.\n",
    "\n",
    "Sorting the dataframe by Group and GroupNumber is useful as it allows us to fill in free cabins in a logical order.\n",
    "\n",
    "With this preparation, we are now ready to proceed with the structured imputation of missing Cabin values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Bills</th>\n",
       "      <th>GroupSize</th>\n",
       "      <th>PotentialDecks</th>\n",
       "      <th>PotentialSides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>Maham</td>\n",
       "      <td>Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Juanna</td>\n",
       "      <td>Vines</td>\n",
       "      <td>736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Altark</td>\n",
       "      <td>Susent</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>02</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Solam</td>\n",
       "      <td>Susent</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Willy</td>\n",
       "      <td>Santantines</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...  GroupNumber  CabinDeck  \\\n",
       "0          0.0        0.0           0.0  ...           01          B   \n",
       "1        109.0        9.0          25.0  ...           01          F   \n",
       "2         43.0     3576.0           0.0  ...           01          A   \n",
       "3          0.0     1283.0         371.0  ...           02          A   \n",
       "4        303.0       70.0         151.0  ...           01          F   \n",
       "\n",
       "  CabinNumber CabinSide FirstName     LastName    Bills GroupSize  \\\n",
       "0           0         P     Maham    Ofracculy      0.0         1   \n",
       "1           0         S    Juanna        Vines    736.0         1   \n",
       "2           0         S    Altark       Susent  10383.0         2   \n",
       "3           0         S     Solam       Susent   5176.0         2   \n",
       "4           1         S     Willy  Santantines   1091.0         1   \n",
       "\n",
       "   PotentialDecks PotentialSides  \n",
       "0            None           None  \n",
       "1            None           None  \n",
       "2            None           None  \n",
       "3            None           None  \n",
       "4            None           None  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataframe with potential decks and sides\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Missing Cabin Values\n",
    "\n",
    "To accurately impute missing Cabin values, we utilize several helper functions. These functions ensure that when a cabin is filled, the corresponding Deck, Number, and Side are also updated. Additionally, we identify potential cabin options for passengers based on the possible decks and sides determined earlier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Helper Function to Impute Cabin Details\n",
    "\n",
    "First, we define a function to fill a Cabin and its corresponding Deck, Number, and Side for a given passenger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to impute cabin details for a given passenger index\n",
    "def impute_from_cabin_and_index(dataframe, cabin, index):\n",
    "    # Split the cabin string into Deck, Number, and Side\n",
    "    cabin_deck = cabin.split(\"/\")[0]\n",
    "    cabin_number = int(cabin.split(\"/\")[1])\n",
    "    cabin_side = cabin.split(\"/\")[2]\n",
    "    \n",
    "    # Update the dataframe with the cabin details\n",
    "    dataframe.loc[index, ['Cabin', 'CabinDeck', 'CabinNumber', 'CabinSide']] = [cabin, cabin_deck, cabin_number, cabin_side]\n",
    "    \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Potential Cabin Options\n",
    "\n",
    "Next, we define a major function to find all the passengers missing a cabin and collect all the cabins they could potentially fill. This is done by examining the potential decks and sides, and determining the available room numbers within those decks and sides. For instance, if Cabin A/02/S was before and A/03/S came after, there is no room in between for the passenger to fill. However, if Cabin A/05/P was before and A/07/P was after, then A/06/P is a potential cabin the passenger could take.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find potential cabin options for passengers missing a cabin\n",
    "def passengers_empty_cabin_options(dataframe):\n",
    "    # Filter dataframe to find passengers without a cabin\n",
    "    df_passengers_without_cabin = dataframe[dataframe['Cabin'].isna()]\n",
    "    \n",
    "    # Dictionary to store potential cabin options for each passenger\n",
    "    all_passenger_cabin_options = {}\n",
    "\n",
    "    # Iterate through each passenger without a cabin\n",
    "    for passenger_index, passenger in df_passengers_without_cabin.iterrows():\n",
    "        all_passenger_cabin_options[passenger_index] = []\n",
    "\n",
    "        # Iterate through each potential deck for the passenger\n",
    "        for deck in passenger.PotentialDecks:\n",
    "            # Iterate through each potential side for the passenger\n",
    "            for side in passenger.PotentialSides:\n",
    "                # Filter dataframe for the current deck and side\n",
    "                df_filtered = dataframe[(dataframe['CabinDeck'] == deck) & (dataframe['CabinSide'] == side)]\n",
    "\n",
    "                # Find the maximum cabin number before the current passenger index\n",
    "                max_cabin_no_before = max(df_filtered.loc[df_filtered.index < passenger_index, 'CabinNumber'].dropna().unique(), default=-1)\n",
    "                \n",
    "                # Find the minimum cabin number after the current passenger index\n",
    "                min_cabin_no_after = min(df_filtered.loc[df_filtered.index > passenger_index, 'CabinNumber'].dropna().unique(), default=-1)\n",
    "\n",
    "                # If no cabins were found of that deck and side before or after the row\n",
    "                if max_cabin_no_before == -1 or min_cabin_no_after == -1:\n",
    "                    continue\n",
    "                \n",
    "                # If there is a gap between the maximum cabin number before and the minimum cabin number after\n",
    "                # Then there are potential cabins the passenger can fill\n",
    "                if max_cabin_no_before + 1 < min_cabin_no_after:\n",
    "                    potential_cabins = [f\"{deck}/{i}/{side}\" for i in range(max_cabin_no_before + 1, min_cabin_no_after)]\n",
    "                    all_passenger_cabin_options[passenger_index].extend(potential_cabins)\n",
    "\n",
    "    return all_passenger_cabin_options\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By identifying the potential cabins for each passenger, we can systematically fill in the missing Cabin values. This ensures that each imputation is consistent with the constraints and assumptions defined earlier.\n",
    "\n",
    "In the next section, we will use these potential cabin options to impute the missing values and complete our dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Cabins for Passengers in Solo Groups with Only One Cabin Option\n",
    "\n",
    "The reasons we can't fill a cabin if the passenger has only one option of cabins from `passengers_empty_cabin_options()` is because the passenger also has an option to share a cabin. This function checks that they are alone in their group, meaning they can't share a cabin with anyone else as they can only share a cabin with a group member (Appendix A.6). If they are alone in their group and they have only one cabin option based on their position onboard, then this cabin will be imputed for them.\n",
    "\n",
    "### Function to Impute Cabins for Solo Group Passengers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to impute cabins for passengers in solo groups with only one cabin option\n",
    "def solo_group_one_cabin_option(dataframe):\n",
    "    # Get potential cabin options for passengers missing a cabin\n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "\n",
    "    # Iterate through passengers who don't have a cabin yet and are alone in their group\n",
    "    for passenger_index in list(dataframe[(dataframe.Cabin.isna()) & (dataframe.GroupSize == 1)].index):\n",
    "        # If they have only one free cabin that they could fill\n",
    "        if len(all_passenger_cabin_options[passenger_index]) == 1:\n",
    "            matching_cabin = all_passenger_cabin_options[passenger_index][0]\n",
    "            dataframe = impute_from_cabin_and_index(dataframe, matching_cabin, passenger_index)\n",
    "\n",
    "    return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By identifying and imputing cabins for passengers who are alone in their group and have only one cabin option, we ensure that these passengers are assigned cabins in a consistent and logical manner.\n",
    "\n",
    "In the next step, we will handle the remaining passengers with missing Cabin values by considering additional constraints and options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Cabins for Passengers with No Suitable Free Cabins\n",
    "\n",
    "The next function handles passengers who do not have any empty cabin options and therefore must share a cabin with a member of their group. Some passengers belong to groups with multiple cabins, which makes it challenging to determine which cabin they should share. This problem is resolved if there is only one cabin in which their group members are present that meets the potential decks and sides requirements.\n",
    "\n",
    "### Function to Impute Cabins for Passengers with No Suitable Free Cabins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to impute cabins for passengers who have no suitable free cabins and must share\n",
    "def no_suitable_cabin_so_shares(dataframe):\n",
    "    # Get potential cabin options for passengers missing a cabin\n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "    \n",
    "    # Iterate through each passenger and their potential cabin options\n",
    "    for passenger_index, passenger_cabin_options in all_passenger_cabin_options.items():\n",
    "        # If there are no free cabins that the passenger can fill\n",
    "        if not passenger_cabin_options:\n",
    "            passenger_row = dataframe.loc[passenger_index]\n",
    "            \n",
    "            # Find all other group members' cabins that are in the same potential decks as the passenger\n",
    "            passengers_group_cabins = dataframe[(dataframe['Group'] == passenger_row['Group']) &\n",
    "                                                (dataframe['CabinDeck'].isin(passenger_row['PotentialDecks']))].Cabin.dropna()\n",
    "            \n",
    "            # If there is only one cabin from their group they could share with\n",
    "            if passengers_group_cabins.nunique() == 1:\n",
    "                matching_cabin = passengers_group_cabins.iloc[0]\n",
    "                dataframe = impute_from_cabin_and_index(dataframe, matching_cabin, passenger_index)\n",
    "                \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By identifying passengers who do not have any suitable free cabins and ensuring they share a cabin with a member of their group, we maintain consistency in the imputation process. This method is only applied when there is a clear, single cabin option that meets all requirements for sharing.\n",
    "\n",
    "With this approach, we further refine our dataset and fill in more missing Cabin values systematically.\n",
    "\n",
    "In the next step, we will handle the remaining passengers with missing Cabin values by considering additional constraints and options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Cabins for the Only Passenger That Can Take a Certain Cabin\n",
    "\n",
    "This final function works based on the assumption that every cabin is filled (i.e., there are no gaps in the cabin numbers). If a passenger is the only one that suits a certain cabin, then that passenger will have that cabin allocated to them.\n",
    "\n",
    "### Function to Impute Cabins for the Only Matching Passenger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Bills</th>\n",
       "      <th>GroupSize</th>\n",
       "      <th>PotentialDecks</th>\n",
       "      <th>PotentialSides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>Maham</td>\n",
       "      <td>Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Juanna</td>\n",
       "      <td>Vines</td>\n",
       "      <td>736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Altark</td>\n",
       "      <td>Susent</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>02</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Solam</td>\n",
       "      <td>Susent</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Willy</td>\n",
       "      <td>Santantines</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...  GroupNumber  CabinDeck  \\\n",
       "0          0.0        0.0           0.0  ...           01          B   \n",
       "1        109.0        9.0          25.0  ...           01          F   \n",
       "2         43.0     3576.0           0.0  ...           01          A   \n",
       "3          0.0     1283.0         371.0  ...           02          A   \n",
       "4        303.0       70.0         151.0  ...           01          F   \n",
       "\n",
       "  CabinNumber CabinSide FirstName     LastName    Bills GroupSize  \\\n",
       "0           0         P     Maham    Ofracculy      0.0         1   \n",
       "1           0         S    Juanna        Vines    736.0         1   \n",
       "2           0         S    Altark       Susent  10383.0         2   \n",
       "3           0         S     Solam       Susent   5176.0         2   \n",
       "4           1         S     Willy  Santantines   1091.0         1   \n",
       "\n",
       "   PotentialDecks PotentialSides  \n",
       "0            None           None  \n",
       "1            None           None  \n",
       "2            None           None  \n",
       "3            None           None  \n",
       "4            None           None  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to impute cabins for the only matching passenger for certain cabins\n",
    "def only_matching_passenger_for_cabin(dataframe):\n",
    "    # Get potential cabin options for passengers missing a cabin\n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "    \n",
    "    # Dictionary to store which passengers can fit each cabin\n",
    "    cabins_to_fill = defaultdict(list)\n",
    "    \n",
    "    # Iterate over each passenger and their potential cabin options\n",
    "    for passenger_index, cabin_options in all_passenger_cabin_options.items():\n",
    "        for cabin in cabin_options:\n",
    "            cabins_to_fill[cabin].append(passenger_index)\n",
    "    \n",
    "    # Iterate over each cabin and impute passengers where only one passenger fits\n",
    "    for cabin, passengers_indices in cabins_to_fill.items():\n",
    "        if len(passengers_indices) == 1:\n",
    "            dataframe = impute_from_cabin_and_index(dataframe, cabin, passengers_indices[0])\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataframe after imputing cabins for the only matching passenger\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By assigning cabins to passengers who are the only ones suitable for certain cabins, we ensure that the imputation process is thorough and consistent. This method helps to finalize the imputation of missing Cabin values by addressing the remaining gaps systematically.\n",
    "\n",
    "With this final step, we have now handled the imputation of Cabin values for all passengers in our dataset, based on the assumptions and constraints defined earlier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation Process\n",
    "\n",
    "As we impute cabins for some passengers, it limits the number of free cabins available for the remaining passengers and reduces the competition to fill certain cabins. By iterating through our imputation functions twice, we ensure that all the cabins that can be found by the functions are filled.\n",
    "\n",
    "### Function to Apply All Imputation Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to apply all imputation steps iteratively\n",
    "def all_imputes(dataframe):\n",
    "    # Apply the imputation functions in sequence\n",
    "    dataframe = solo_group_one_cabin_option(dataframe)\n",
    "    dataframe = no_suitable_cabin_so_shares(dataframe)\n",
    "    dataframe = only_matching_passenger_for_cabin(dataframe)\n",
    "\n",
    "    # Apply the imputation functions again to ensure thorough filling of cabins\n",
    "    dataframe = solo_group_one_cabin_option(dataframe)\n",
    "    dataframe = no_suitable_cabin_so_shares(dataframe)\n",
    "    dataframe = only_matching_passenger_for_cabin(dataframe)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# Apply the all_imputes function to the dataframe\n",
    "df = all_imputes(df)\n",
    "\n",
    "# Check the number of missing values in the Cabin column after imputation\n",
    "df.Cabin.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the imputation functions twice, we ensure that all possible cabin assignments are made. This approach helps to systematically reduce the number of missing Cabin values, making our dataset more complete and accurate.\n",
    "\n",
    "With this final imputation process, we have successfully filled as many missing Cabin values as possible based on the constraints and assumptions defined earlier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 37 cabins that still remain unfilled, and we started with 299! There are still a few more that we can find that those functions did not cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Imputation of Remaining Cabins\n",
    "\n",
    "After applying our imputation functions, 37 cabins still remain unfilled. To address these, we can manually deduce some of the remaining cabins using a helper function that prints out useful data for each passenger with missing cabin information. This function will provide insights into the potential cabin options for each passenger, which can help us manually impute the remaining cabins.\n",
    "\n",
    "### Function to Print Cabin Options for Each Passenger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to print potential cabin options for each passenger with missing cabin information\n",
    "def all_cabin_options_for_each_row(dataframe):\n",
    "    # Get potential cabin options for passengers missing a cabin\n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "    \n",
    "    # Iterate through each passenger and their potential cabin options\n",
    "    for passenger_index, passenger_options in all_passenger_cabin_options.items():\n",
    "        print()\n",
    "        print(\"PassengerId:\", dataframe.iloc[passenger_index].PassengerId, \"GroupSize:\", dataframe.iloc[passenger_index].GroupSize)\n",
    "        print(\"Free cabins that match:\")\n",
    "        print(passenger_options)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By printing out the potential cabin options for each passenger with missing cabin information, we can manually review and deduce the best possible cabin assignments for the remaining passengers. This manual step ensures that we leave no stone unturned in our imputation process.\n",
    "\n",
    "With these insights, we can further reduce the number of missing Cabin values and improve the completeness of our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PassengerId: 0293_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "\n",
      "PassengerId: 0310_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "\n",
      "PassengerId: 0348_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 0364_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 0374_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 1011_01 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/58/P']\n",
      "\n",
      "PassengerId: 1041_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S', 'E/58/P']\n",
      "\n",
      "PassengerId: 1095_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S']\n",
      "\n",
      "PassengerId: 1709_03 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 2092_03 GroupSize: 5\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 2513_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "\n",
      "PassengerId: 2514_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "\n",
      "PassengerId: 3034_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/98/P', 'B/99/P']\n",
      "\n",
      "PassengerId: 3053_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/98/P', 'B/99/P']\n",
      "\n",
      "PassengerId: 3287_02 GroupSize: 3\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 3411_02 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 3598_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "\n",
      "PassengerId: 3599_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "\n",
      "PassengerId: 4637_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/300/S', 'E/301/S']\n",
      "\n",
      "PassengerId: 4652_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/300/S', 'E/301/S']\n",
      "\n",
      "PassengerId: 6028_04 GroupSize: 5\n",
      "Free cabins that match:\n",
      "['D/191/P']\n",
      "\n",
      "PassengerId: 6048_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "\n",
      "PassengerId: 6060_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "\n",
      "PassengerId: 7182_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "\n",
      "PassengerId: 7183_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "\n",
      "PassengerId: 7353_03 GroupSize: 3\n",
      "Free cabins that match:\n",
      "['C/270/S']\n",
      "\n",
      "PassengerId: 7368_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/270/S', 'D/235/P']\n",
      "\n",
      "PassengerId: 7429_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/235/P', 'F/1424/S']\n",
      "\n",
      "PassengerId: 7440_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1424/S', 'G/1206/S']\n",
      "\n",
      "PassengerId: 7442_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['G/1206/S']\n",
      "\n",
      "PassengerId: 7463_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'F/1424/S', 'G/1212/S']\n",
      "\n",
      "PassengerId: 7469_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'G/1212/S']\n",
      "\n",
      "PassengerId: 7983_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "\n",
      "PassengerId: 7995_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "\n",
      "PassengerId: 8728_07 GroupSize: 8\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 9223_01 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['F/1785/S']\n",
      "\n",
      "PassengerId: 9223_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['F/1785/S']\n"
     ]
    }
   ],
   "source": [
    "all_cabin_options_for_each_row(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Imputation Reasoning\n",
    "\n",
    "Despite our algorithmic efforts, some cabins remain unfilled due to specific constraints and options available. By analyzing the potential options for these passengers manually, we can deduce the best possible cabin assignments for the remaining cases.\n",
    "\n",
    "### Manual Imputation Details\n",
    "\n",
    "1. **Passenger 1011_01, Cabin E/58/P**\n",
    "   - The cabin can only be filled by 1011_01 and 1041_01. However, one of 1041_01 and 1095_01 has to fill C/40/S, and the other has to fill D/36/S, as they are the only two that can fill these cabins. This leaves passenger 1011_01 to fill E/58/P.\n",
    "\n",
    "2. **Passengers 3034_01, 3053_01, Cabins B/98/P, B/99/P**\n",
    "   - These passengers weren't filled as the consecutive free cabins showed multiple options. As no one else can fill these cabins and index 3034_01 comes before 3053_01, they are filled in that order.\n",
    "\n",
    "3. **Passengers 4637_01, 4652_01, Cabins E/300/S, E/301/S**\n",
    "   - These passengers are the only two that can fill these cabins. They weren't imputed earlier as the free cabins are consecutive.\n",
    "\n",
    "4. **Passenger 6028_04, Cabin A/57/P**\n",
    "   - Since 6060_01 and 6048_01 are each alone in their groups with only two cabins to fill, one must fill D/191/P, and the other must fill E/387/P. This leaves index 6028_04 no other option but to join the only cabin that the rest of its group is in.\n",
    "\n",
    "5. **Passengers 9223_01, 9223_02, Cabin F/1785/S**\n",
    "   - These two passengers are the only members of their group and have one option for a cabin, so they both must share F/1785/S.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of manually determined cabin assignments\n",
    "cabin_list = [\n",
    "    (1429, 'E/58/P'), (4233, 'B/98/P'), (4254, 'B/99/P'), \n",
    "    (6493, 'E/300/S'), (6514, 'E/301/S'), (8413, 'A/57/P'), \n",
    "    (12892, 'F/1785/S'), (12893, 'F/1785/S')\n",
    "]\n",
    "\n",
    "# Apply the manual imputation\n",
    "for index, cabin in cabin_list:\n",
    "    df = impute_from_cabin_and_index(df, cabin, index)\n",
    "\n",
    "# Check the number of missing values in the Cabin column after manual imputation\n",
    "df.Cabin.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By manually reviewing and assigning the remaining cabins based on the detailed reasoning, we ensure that these final imputed values are consistent with our earlier assumptions and constraints. This step further reduces the number of missing Cabin values, enhancing the completeness and accuracy of our dataset.\n",
    "\n",
    "With these manual imputations, we have now addressed the remaining missing Cabin values, achieving a more comprehensive imputation process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have successfully imputed most of the missing Cabin values, reducing the number of unfilled cabins from 299 to just 29. This significant reduction should help improve our standings in the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thank you for making it this far! This project required a significant amount of effort and dedication to address the complex problem of imputing missing cabin values. By meticulously analyzing the data and applying structured algorithms, we have managed to reduce the number of missing cabins from 299 to just 29. This progress is a testament to the power of data-driven approaches and careful reasoning.**\n",
    "\n",
    "**I sincerely hope that the techniques and insights shared in this notebook will be beneficial for your own projects and help you climb the leaderboard. If you found this work helpful, I would greatly appreciate your upvotes and feedback. It would mean a lot to know that my contributions are making a positive impact.**\n",
    "\n",
    "**Best of luck with your submissions, and may this notebook serve as a valuable resource in your data science journey. If you have any further questions or if new inferences come to light, please feel free to reach out. Together, we can continue to improve and refine our approaches.**\n",
    "\n",
    "**Thank you once again for your time and effort in reviewing this work. Your support and encouragement are much appreciated!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Next, we will split the data back into the training and test sets. Additionally, I will detail the reasoning behind the remaining 29 passengers and explain why we cannot yet decide which cabin they should take. If any new inferences come to light, please let me know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Bills</th>\n",
       "      <th>GroupSize</th>\n",
       "      <th>PotentialDecks</th>\n",
       "      <th>PotentialSides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>Nelly</td>\n",
       "      <td>Carsoning</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>S</td>\n",
       "      <td>Lerome</td>\n",
       "      <td>Peckers</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Sabih</td>\n",
       "      <td>Unhearfus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Meratz</td>\n",
       "      <td>Caltilter</td>\n",
       "      <td>7418.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>S</td>\n",
       "      <td>Brence</td>\n",
       "      <td>Harperez</td>\n",
       "      <td>645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "16     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
       "22     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
       "23     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
       "30     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
       "32     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
       "\n",
       "    RoomService  FoodCourt  ShoppingMall  ...  GroupNumber  CabinDeck  \\\n",
       "16          0.0        0.0           0.0  ...           01          G   \n",
       "22          0.0        9.0           0.0  ...           01          F   \n",
       "23          0.0        0.0           0.0  ...           01          C   \n",
       "30          0.0     6652.0           0.0  ...           01          C   \n",
       "32         10.0        0.0         635.0  ...           01          F   \n",
       "\n",
       "   CabinNumber CabinSide FirstName   LastName   Bills GroupSize  \\\n",
       "16           3         S     Nelly  Carsoning     0.0         1   \n",
       "22           4         S    Lerome    Peckers  2832.0         1   \n",
       "23           0         S     Sabih  Unhearfus     0.0         1   \n",
       "30           1         S    Meratz  Caltilter  7418.0         1   \n",
       "32           5         S    Brence   Harperez   645.0         1   \n",
       "\n",
       "    PotentialDecks PotentialSides  \n",
       "16            None           None  \n",
       "22            None           None  \n",
       "23            None           None  \n",
       "30            None           None  \n",
       "32            None           None  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data back into training and test sets\n",
    "traindata = df[df.Set == 'Train']\n",
    "testdata = df[df.Set == 'Test']\n",
    "\n",
    "# Check the number of missing values in the Cabin column after manual imputation\n",
    "df.Cabin.isna().sum()\n",
    "\n",
    "# Display the first few rows of the training and test data\n",
    "traindata.head()\n",
    "testdata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PassengerId: 0293_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "\n",
      "PassengerId: 0310_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "\n",
      "PassengerId: 0348_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 0364_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 0374_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 1041_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S']\n",
      "\n",
      "PassengerId: 1095_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S']\n",
      "\n",
      "PassengerId: 1709_03 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 2092_03 GroupSize: 5\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 2513_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "\n",
      "PassengerId: 2514_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "\n",
      "PassengerId: 3287_02 GroupSize: 3\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 3411_02 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 3598_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "\n",
      "PassengerId: 3599_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "\n",
      "PassengerId: 6048_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "\n",
      "PassengerId: 6060_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "\n",
      "PassengerId: 7182_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "\n",
      "PassengerId: 7183_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "\n",
      "PassengerId: 7353_03 GroupSize: 3\n",
      "Free cabins that match:\n",
      "['C/270/S']\n",
      "\n",
      "PassengerId: 7368_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/270/S', 'D/235/P']\n",
      "\n",
      "PassengerId: 7429_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/235/P', 'F/1424/S']\n",
      "\n",
      "PassengerId: 7440_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1424/S', 'G/1206/S']\n",
      "\n",
      "PassengerId: 7442_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['G/1206/S']\n",
      "\n",
      "PassengerId: 7463_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'F/1424/S', 'G/1212/S']\n",
      "\n",
      "PassengerId: 7469_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'G/1212/S']\n",
      "\n",
      "PassengerId: 7983_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "\n",
      "PassengerId: 7995_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "\n",
      "PassengerId: 8728_07 GroupSize: 8\n",
      "Free cabins that match:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "all_cabin_options_for_each_row(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Remaining Missing Cabins\n",
    "\n",
    "Despite our best efforts, there are still 29 cabins that remain unfilled. Here, we provide details about these remaining cases and the reasoning behind why we couldn't impute them:\n",
    "\n",
    "#### Cases of Two Passengers Alone in Their Group with Two Suitable Cabins\n",
    "1. **Passengers 0293_01 and 0310_01**: Cabins B/13/P and C/13/S\n",
    "2. **Passengers 1041_01 and 1095_01**: Cabins C/40/S and D/36/S\n",
    "3. **Passengers 2513_01 and 2514_01**: Cabins E/150/P and F/519/P\n",
    "4. **Passengers 3598_01 and 3599_01**: Cabins G/590/P and G/579/S\n",
    "5. **Passengers 6048_01 and 6048_01**: Cabins D/191/P and E/387/P\n",
    "6. **Passengers 7182_01 and 7183_01**: Cabins F/1489/P and G/1157/P\n",
    "7. **Passengers 7463_01 and 7469_01**: Cabins F/1544/P and G/1212/S\n",
    "    - Passenger 7463_01 also has the option of F/1424/S, but as 7463_01 and 7469_01 are the only passengers that can take F/1544/P and G/1212/S, logically 7463_01 must take one of F/1544/P or G/1212/S, and 7469_01 must take the other.\n",
    "8. **Passengers 7983_01 and 7995_01**: Cabins C/298/S and E/528/S\n",
    "\n",
    "#### Cases of Passengers Who Have to Share a Cabin with a Group Member, but There Are Multiple Suitable Cabins\n",
    "1. **Passenger 1709_03**: Cabins F/326/S, D/61/S, E/127/S\n",
    "2. **Passenger 2092_03**: Cabins D/70/S, E/153/S, F/410/S\n",
    "3. **Passenger 3287_02**: Cabins G/522/S, F/621/S\n",
    "4. **Passenger 3411_02**: Cabins E/232/S, F/645/S\n",
    "5. **Passenger 8728_07**: Cabins F/1798/P, G/1416/P\n",
    "\n",
    "#### Other Cases\n",
    "1. **Passengers 0348_02, 0364_02, and 0374_02**: Each of these passengers is in a group of 2 and can only take cabins E/20/P and E/21/P, meaning that one of them shares with their group member, and the other two take those cabins.\n",
    "2. **Passenger 7353_03**: Either takes cabin C/270/S and then:\n",
    "    - Passenger 7368_01 takes D/235/P\n",
    "    - Passenger 7429_01 takes F/1424/S\n",
    "    - Passenger 7503_02 takes G/1206/S\n",
    "    - Passenger 7442_02 shares E/495/S with a group member\n",
    "    Or:\n",
    "    - Passenger 7353_03 shares C/269/S with a group member, and then:\n",
    "    - Passenger 7368_01 takes C/270/S\n",
    "    - Passenger 7429_01 takes D/235/P\n",
    "    - Passenger 7503_02 takes F/1424/S\n",
    "    - Passenger 7442_02 takes G/1206/S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Assumptions\n",
    "\n",
    "There aren't more cabins available than we have assumed. While working on this project, I initially missed imputing many cabins due to the belief that cabin numbers could extend beyond what we observed. However, after assuming that cabins do not extend beyond the observed numbers, the passengers all fit within the given constraints. This seemed unlikely if there were more cabins available than assumed, as we did not find any passengers without options or rooms without matching passengers.\n",
    "\n",
    "In conclusion, this project has significantly improved the completeness of our dataset by reducing the number of missing Cabin values from 299 to just 29. These remaining cases present complex scenarios that require further inference or additional data to resolve. If new patterns or information emerge, we can continue to refine our imputation strategy to achieve even higher accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_comp = pd.read_csv('data/31remaining.csv')\n",
    "df_to_comp = df_to_comp.rename(columns = {'Number':'CabinNumber'})\n",
    "df_to_comp['CabinNumber'] = df_to_comp['CabinNumber'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9267 G/1077/S F/1267/S\n",
      "12651 A/94/P nan\n",
      "12668 B/297/P nan\n"
     ]
    }
   ],
   "source": [
    "for index,row in df.iterrows():\n",
    "    if not (pd.isna(row.Cabin) and pd.isna(df_to_comp.iloc[index].Cabin)):\n",
    "        if row.Cabin != df_to_comp.iloc[index].Cabin:\n",
    "            print(index,row.Cabin, df_to_comp.iloc[index].Cabin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Evidence in the Appendix I will reuse the combined original dataframes without any imputations as to not misrepresent the underlying distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "df = pd.concat([training_data,test_data]) \n",
    "\n",
    "df = column_splits(df)\n",
    "df = df.sort_values(by = ['Group','GroupNumber'])\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of passengers sharing a group implying that their cabin is on the same side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with consistent cabin sides: 5825\n",
      "Number of rows with inconsistent cabin sides: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Group' and check if all non-NaN 'CabinSide' values within each group are the same\n",
    "consistent_count = 0\n",
    "inconsistent_count = 0\n",
    "\n",
    "# Iterate through each group\n",
    "for group, group_df in df.groupby('Group'):\n",
    "    if len(group_df) > 1:\n",
    "        # Get unique non-NaN CabinSide values\n",
    "        unique_sides = group_df['CabinSide'].dropna().unique()\n",
    "        \n",
    "        if len(unique_sides) <= 1:\n",
    "            # All rows in this group are consistent\n",
    "            consistent_count += len(group_df)\n",
    "        else:\n",
    "            # Some rows in this group are inconsistent\n",
    "            inconsistent_count += len(group_df)\n",
    "\n",
    "print(f\"Number of rows with consistent cabin sides: {consistent_count}\")\n",
    "print(f\"Number of rows with inconsistent cabin sides: {inconsistent_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of passengers sharing a group implying that they have the same home planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with consistent home planets: 5825\n",
      "Number of rows with inconsistent home planets: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "planet_consistent_count = 0\n",
    "planet_inconsistent_count = 0\n",
    "\n",
    "# Iterate through each group\n",
    "for group, group_df in df.groupby('Group'):\n",
    "    if len(group_df) > 1:\n",
    "    # Get unique non-NaN HomePlanet values\n",
    "        unique_home_planets = group_df['HomePlanet'].dropna().unique()\n",
    "        \n",
    "        if len(unique_home_planets) <= 1:\n",
    "            # All rows in this group are consistent in HomePlanet\n",
    "            planet_consistent_count += len(group_df)\n",
    "        else:\n",
    "            # Some rows in this group are inconsistent in HomePlanet\n",
    "            planet_inconsistent_count += len(group_df)\n",
    "\n",
    "print(f\"Number of rows with consistent home planets: {planet_consistent_count}\")\n",
    "print(f\"Number of rows with inconsistent home planets: {planet_inconsistent_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of passengers sharing a last name implying that they have the same home planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with consistent home planets by last name: 12468\n",
      "Number of rows with inconsistent home planets by last name: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "planet_consistent_count = 0\n",
    "planet_inconsistent_count = 0\n",
    "\n",
    "# Iterate through each last name group\n",
    "for last_name, group_df in df.groupby('LastName'):\n",
    "    if len(group_df) > 1:  # Exclude last names with only one passenger\n",
    "        # Get unique non-NaN HomePlanet values\n",
    "        unique_home_planets = group_df['HomePlanet'].dropna().unique()\n",
    "        \n",
    "        if len(unique_home_planets) <= 1:\n",
    "            # All rows in this group are consistent in HomePlanet\n",
    "            planet_consistent_count += len(group_df)\n",
    "        else:\n",
    "            # Some rows in this group are inconsistent in HomePlanet\n",
    "            planet_inconsistent_count += len(group_df)\n",
    "\n",
    "print(f\"Number of rows with consistent home planets by last name: {planet_consistent_count}\")\n",
    "print(f\"Number of rows with inconsistent home planets by last name: {planet_inconsistent_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of children under the age of 13 having no bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bills'] = df['RoomService'] + df['FoodCourt'] + df['ShoppingMall'] + df['Spa'] + df['VRDeck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for passengers under the age of 13 (excluding NaN Bills):\n",
      "   Total Under 13  Bills = 0  Bills != 0  Consistency Ratio\n",
      "0            1030       1030           0                1.0\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows with NaN values in Bills\n",
    "df_filtered = df[df['Bills'].notna()]\n",
    "\n",
    "# Check if passengers under the age of 13 have bills = 0\n",
    "under_13 = df_filtered[df_filtered['Age'] < 13]\n",
    "under_13_bills_zero = under_13['Bills'] == 0\n",
    "\n",
    "# Calculate summary statistics\n",
    "total_under_13 = len(under_13)\n",
    "bills_zero_under_13 = under_13_bills_zero.sum()\n",
    "bills_not_zero_under_13 = total_under_13 - bills_zero_under_13\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Total Under 13': [total_under_13],\n",
    "    'Bills = 0': [bills_zero_under_13],\n",
    "    'Bills != 0': [bills_not_zero_under_13],\n",
    "    'Consistency Ratio': [bills_zero_under_13 / total_under_13]\n",
    "})\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Summary statistics for passengers under the age of 13 (excluding NaN Bills):\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of those in CryoSleep having no bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for passengers under the age of 13 (excluding NaN Bills):\n",
      "   Total CryoSleep  Bills == 0  Bills != 0  Consistency Ratio\n",
      "0             4068        4068           0                1.0\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows with NaN values in Bills\n",
    "df_filtered = df[df['Bills'].notna()]\n",
    "\n",
    "# Check if passengers under the age of 13 have bills = 0\n",
    "cryo = df_filtered[df_filtered['CryoSleep'] == True]\n",
    "cryo_bills_zero = cryo['Bills'] == 0\n",
    "\n",
    "# Calculate summary statistics\n",
    "total_in_cryo = len(cryo)\n",
    "cryo_bills_zero = cryo_bills_zero.sum()\n",
    "cryo_bills_not_zero = total_in_cryo - cryo_bills_zero\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Total CryoSleep': [total_in_cryo],\n",
    "    'Bills == 0': [cryo_bills_zero],\n",
    "    'Bills != 0': [cryo_bills_not_zero],\n",
    "    'Consistency Ratio': [cryo_bills_zero / total_in_cryo]\n",
    "})\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Summary statistics for passengers under the age of 13 (excluding NaN Bills):\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabins shared by more than one group (with more than one member):\n",
      "Series([], Name: Group, dtype: object)\n",
      "\n",
      "Total multi-member cabins: 1684\n",
      "Multi-member cabins shared by multiple groups: 0\n",
      "Multi-member cabins unique to one group: 1684\n"
     ]
    }
   ],
   "source": [
    "# Filter cabins with more than one member\n",
    "cabin_counts = df['Cabin'].value_counts()\n",
    "multi_member_cabins = cabin_counts[cabin_counts > 1].index\n",
    "\n",
    "# Group by Cabin and list unique groups for each Cabin with more than one member\n",
    "cabin_group_mapping = df[df['Cabin'].isin(multi_member_cabins)].groupby('Cabin')['Group'].unique()\n",
    "\n",
    "# Check if any Cabin is associated with more than one group\n",
    "shared_cabins = cabin_group_mapping[cabin_group_mapping.apply(lambda groups: len(groups) > 1)]\n",
    "\n",
    "# Print the results\n",
    "print(\"Cabins shared by more than one group (with more than one member):\")\n",
    "print(shared_cabins)\n",
    "\n",
    "# Summary statistics\n",
    "total_multi_member_cabins = len(cabin_group_mapping)\n",
    "shared_cabin_count = len(shared_cabins)\n",
    "unique_cabin_count = total_multi_member_cabins - shared_cabin_count\n",
    "\n",
    "print(f\"\\nTotal multi-member cabins: {total_multi_member_cabins}\")\n",
    "print(f\"Multi-member cabins shared by multiple groups: {shared_cabin_count}\")\n",
    "print(f\"Multi-member cabins unique to one group: {unique_cabin_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix B\n",
    "Evidence of Home Planets Restricting Which Deck a Passenger's Cabin is On\n",
    "We have observed that certain home planets restrict which decks their passengers' cabins are on. To provide evidence of this pattern, we analyze the data by grouping it based on 'HomePlanet' and 'CabinDeck', and counting the occurrences of each combination.\n",
    "\n",
    "Grouping by HomePlanet and CabinDeck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet  Earth  Europa  Mars\n",
      "CabinDeck                      \n",
      "A               0     346     0\n",
      "B               0    1124     0\n",
      "C               0    1081     0\n",
      "D               0     296   406\n",
      "E             583     197   508\n",
      "F            2426       0  1713\n",
      "G            3700       0     0\n",
      "T               0      10     0\n"
     ]
    }
   ],
   "source": [
    "# Group by 'HomePlanet' and 'CabinDeck' and count occurrences\n",
    "deck_counts = df.groupby(['HomePlanet', 'CabinDeck']).size().reset_index(name='Count')\n",
    "\n",
    "# Pivot the table to get a better overview\n",
    "pivot_table = deck_counts.pivot(index='CabinDeck', columns='HomePlanet', values='Count').fillna(0).astype(int)\n",
    "\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence from Passengers with Bills = 0 in Groups with Multiple CabinDecks\n",
    "To further support our assumption, we analyze passengers who have bills equal to 0 and belong to groups with multiple CabinDecks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CabinDecks for passengers with bills = 0 in groups with multiple CabinDecks:\n",
      "HomePlanet: Earth\n",
      "  CabinDeck: G, Count: 526\n",
      "HomePlanet: Mars\n",
      "  CabinDeck: F, Count: 160\n",
      "  CabinDeck: E, Count: 47\n",
      "HomePlanet: Europa\n",
      "  CabinDeck: B, Count: 11\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Iterate through each group\n",
    "for group, group_df in df.groupby('Group'):\n",
    "    # Check if within the group there are more than one CabinDeck\n",
    "    unique_decks = group_df['CabinDeck'].dropna().unique()\n",
    "    \n",
    "    if len(unique_decks) > 1:\n",
    "        # Find passengers with bills = 0\n",
    "        zero_bill_passengers = group_df[(group_df['Bills'] == 0)  & (group_df['HomePlanet'].notna())]\n",
    "        \n",
    "        for idx, passenger in zero_bill_passengers.iterrows():\n",
    "            home_planet = passenger['HomePlanet']\n",
    "            cabin_deck = passenger['CabinDeck']\n",
    "            \n",
    "            if home_planet not in results:\n",
    "                results[home_planet] = []\n",
    "            \n",
    "            results[home_planet].append(cabin_deck)\n",
    "\n",
    "# Print the results\n",
    "print(\"CabinDecks for passengers with bills = 0 in groups with multiple CabinDecks:\")\n",
    "for home_planet, cabin_decks in results.items():\n",
    "    cabin_deck_counts = pd.Series(cabin_decks).value_counts().to_dict()\n",
    "    print(f\"HomePlanet: {home_planet}\")\n",
    "    for deck, count in cabin_deck_counts.items():\n",
    "        print(f\"  CabinDeck: {deck}, Count: {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spaceenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
