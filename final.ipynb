{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "In this notebook, I will demonstrate an algorithmic approach to fill in (nearly) every missing Cabin value in the Space Titanic dataset. Unlike probabilistic or guessing methods, this approach follows a structured order based on each passenger's Homeplanet and group (derived from their PassengerID).\n",
    "\n",
    "Cabins are filled sequentially based on their numbers. For instance, if a passenger is assigned to cabin A/05/P, a passenger in a subsequent group cannot be assigned to A/04/P. However, they could be assigned to A/01/S or B/01/P.\n",
    "\n",
    "By employing this method, we aim to achieve a more accurate and logical imputation of missing Cabin values, which will improve the performance of our predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Cabin and PassengerID Components and Assumptions\n",
    "\n",
    "The Cabin column in the dataset is structured in the format A/01/P, where:\n",
    "\n",
    "- **A**: Cabin deck, which can take values 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'\n",
    "- **01**: Cabin number, which can take values 0, 1, 2, ...\n",
    "- **P**: Cabin side, which can take values 'P' (Port) or 'S' (Starboard)\n",
    "\n",
    "The PassengerId column in the dataset is structured in the format 0201_01, where:\n",
    "- **0201**: Group, these codes correspond to other members of the same group\n",
    "- **01**: Group number, always starts at 1 and will cout how many members there are in a group\n",
    "\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "To facilitate our imputation approach, we make several key assumptions:\n",
    "\n",
    "1. **Group Members Share the Same Side**: If two passengers are in the same group, they are on the same side of the ship. (Appendix A.1)\n",
    "2. **Group Members Share the Same Home Planet**: If two passengers are in the same group, they originate from the same home planet. (Appendix A.2)\n",
    "3. **Shared Last Names Indicate Same Home Planet**: Passengers sharing a last name are from the same home planet. (Appendix A.3)\n",
    "4. **Children Have No Bills**: Passengers aged 12 or younger do not incur any bills. (Appendix A.4)\n",
    "5. **Cryosleep Implies No Bills**: Passengers who are in cryosleep do not incur any bills. (Appendix A.5)\n",
    "6. **Cabins Shared Within Groups**: Cabins can only be shared by members of the same group. (Appendix A.6)\n",
    "7. **Home Planets and Deck Restrictions**: Passengers' home planets restrict which decks they can be assigned to. (Appendix B)\n",
    "    - **Mars**: Decks 'D', 'E', or 'F'\n",
    "    - **Earth**: Decks 'E', 'F', or 'G'\n",
    "    - **Europa**: Decks 'A', 'B', 'C', 'D', 'E', or 'T'\n",
    "    - Passengers with no bills and group members on different decks have further restrictions:\n",
    "        - **Earth**: Restricted to deck 'G'\n",
    "        - **Europa**: Restricted to deck 'B'\n",
    "        - **Mars**: Restricted to decks 'E' and 'F'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maintain the order of passengers by group, we combine the training and test datasets. This combined dataframe will be used for the rest of the project, ensuring consistency in our imputation process.\n",
    "\n",
    "By combining the datasets, we have a more comprehensive view of all passengers, which will aid in the structured filling of missing Cabin values.\n",
    "\n",
    "Below is the code to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "  Transported    Set  \n",
       "0       False  Train  \n",
       "1        True  Train  \n",
       "2       False  Train  \n",
       "3       False  Train  \n",
       "4        True  Train  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd \n",
    "from collections import defaultdict # Slightly modified from a regular dictionary\n",
    "\n",
    "# Load the training and test data\n",
    "training_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Add a column to distinguish between the training and test sets\n",
    "training_data['Set'] = 'Train'\n",
    "test_data['Set'] = 'Test'\n",
    "\n",
    "# Combine the training and test datasets\n",
    "df = pd.concat([training_data, test_data])\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we perform several essential preprocessing steps to prepare our data for imputation and analysis. These steps include splitting relevant columns, sorting the dataframe, and handling missing values in a structured manner.\n",
    "\n",
    "First, let's verify the number of missing Cabin values in our combined dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our starting point, and we have identified that there are 299 missing Cabin values. Our next step will be to address these missing values systematically using the assumptions defined earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of missing values in the Cabin column\n",
    "df['Cabin'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split the unique PassengerId into Group and their number in the group, split the Cabin into deck, side, and number, and split their names into first and last name. This segmentation helps us leverage the information contained within these columns more effectively.\n",
    "\n",
    "Here is the code to achieve these splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Set</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "      <td>0001</td>\n",
       "      <td>01</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>Maham</td>\n",
       "      <td>Ofracculy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "      <td>0002</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Juanna</td>\n",
       "      <td>Vines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>01</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Altark</td>\n",
       "      <td>Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>02</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Solam</td>\n",
       "      <td>Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "      <td>Train</td>\n",
       "      <td>0004</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Willy</td>\n",
       "      <td>Santantines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...               Name  Transported  \\\n",
       "0          0.0        0.0           0.0  ...    Maham Ofracculy        False   \n",
       "1        109.0        9.0          25.0  ...       Juanna Vines         True   \n",
       "2         43.0     3576.0           0.0  ...      Altark Susent        False   \n",
       "3          0.0     1283.0         371.0  ...       Solam Susent        False   \n",
       "4        303.0       70.0         151.0  ...  Willy Santantines         True   \n",
       "\n",
       "     Set Group GroupNumber CabinDeck CabinNumber CabinSide  FirstName  \\\n",
       "0  Train  0001          01         B           0         P      Maham   \n",
       "1  Train  0002          01         F           0         S     Juanna   \n",
       "2  Train  0003          01         A           0         S     Altark   \n",
       "3  Train  0003          02         A           0         S      Solam   \n",
       "4  Train  0004          01         F           1         S      Willy   \n",
       "\n",
       "      LastName  \n",
       "0    Ofracculy  \n",
       "1        Vines  \n",
       "2       Susent  \n",
       "3       Susent  \n",
       "4  Santantines  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to split columns into multiple components\n",
    "def column_splits(data_frame):\n",
    "    # Split PassengerId into Group and GroupNumber\n",
    "    data_frame[['Group', 'GroupNumber']] = data_frame['PassengerId'].str.split('_', expand=True)\n",
    "    \n",
    "    # Split Cabin into CabinDeck, CabinNumber, and CabinSide\n",
    "    data_frame[['CabinDeck', 'CabinNumber', 'CabinSide']] = data_frame['Cabin'].str.split(\"/\", expand=True)\n",
    "    data_frame['CabinNumber'] = data_frame['CabinNumber'].astype('Int64')\n",
    "    \n",
    "    # Split Name into FirstName and LastName\n",
    "    data_frame[['FirstName', 'LastName']] = data_frame['Name'].str.split(\" \", expand=True)\n",
    "\n",
    "    return data_frame\n",
    "\n",
    "# Apply the function to the combined dataframe\n",
    "df = column_splits(df)\n",
    "\n",
    "# Sort the dataframe by Group and GroupNumber\n",
    "df = df.sort_values(by=['Group', 'GroupNumber'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the modified dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total bills are composed of the summation of each passengers roomservice, foodcourt, shoppingmall, spa and vrdeck payments.\n",
    "We can impute bills to be equal to 0 if someone is under 13 and/or they are in cryosleep (Appendix A.4,A.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total bills for each passenger\n",
    "df['Bills'] = df['RoomService'] + df['FoodCourt'] + df['ShoppingMall'] + df['Spa'] + df['VRDeck']\n",
    "\n",
    "# Impute bills to be zero for passengers under 13 or in cryosleep\n",
    "df.loc[df['Age'] < 13, 'Bills'] = 0\n",
    "df.loc[df['CryoSleep'] == True, 'Bills'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add a useful column to our dataframe: GroupSize, which indicates the number of passengers in each group. This helps us understand group dynamics and may assist in the imputation process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>Set</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Bills</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0001</td>\n",
       "      <td>01</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>Maham</td>\n",
       "      <td>Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0002</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Juanna</td>\n",
       "      <td>Vines</td>\n",
       "      <td>736.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>01</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Altark</td>\n",
       "      <td>Susent</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>02</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Solam</td>\n",
       "      <td>Susent</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0004</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Willy</td>\n",
       "      <td>Santantines</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...    Set  Group GroupNumber  \\\n",
       "0          0.0        0.0           0.0  ...  Train   0001          01   \n",
       "1        109.0        9.0          25.0  ...  Train   0002          01   \n",
       "2         43.0     3576.0           0.0  ...  Train   0003          01   \n",
       "3          0.0     1283.0         371.0  ...  Train   0003          02   \n",
       "4        303.0       70.0         151.0  ...  Train   0004          01   \n",
       "\n",
       "  CabinDeck CabinNumber CabinSide FirstName     LastName    Bills GroupSize  \n",
       "0         B           0         P     Maham    Ofracculy      0.0         1  \n",
       "1         F           0         S    Juanna        Vines    736.0         1  \n",
       "2         A           0         S    Altark       Susent  10383.0         2  \n",
       "3         A           0         S     Solam       Susent   5176.0         2  \n",
       "4         F           1         S     Willy  Santantines   1091.0         1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to add a GroupSize column\n",
    "def add_group_size_column(dataframe):\n",
    "    dataframe['GroupSize'] = dataframe.groupby('Group')['Group'].transform('count')\n",
    "    return dataframe\n",
    "\n",
    "# Apply the function to the combined dataframe\n",
    "df = add_group_size_column(df)\n",
    "\n",
    "# Display the first few rows of the dataframe with the new GroupSize column\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further enhance our dataset, we define a function to impute missing values based on shared features. For instance, rows with missing values for HomePlanet can be imputed if they share a group with someone whose HomePlanet is known or share a last name with someone whose HomePlanet is known (Appendix A.2, A.3):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>Set</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Bills</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0001</td>\n",
       "      <td>01</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>Maham</td>\n",
       "      <td>Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0002</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Juanna</td>\n",
       "      <td>Vines</td>\n",
       "      <td>736.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>01</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Altark</td>\n",
       "      <td>Susent</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0003</td>\n",
       "      <td>02</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Solam</td>\n",
       "      <td>Susent</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0004</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Willy</td>\n",
       "      <td>Santantines</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...    Set  Group GroupNumber  \\\n",
       "0          0.0        0.0           0.0  ...  Train   0001          01   \n",
       "1        109.0        9.0          25.0  ...  Train   0002          01   \n",
       "2         43.0     3576.0           0.0  ...  Train   0003          01   \n",
       "3          0.0     1283.0         371.0  ...  Train   0003          02   \n",
       "4        303.0       70.0         151.0  ...  Train   0004          01   \n",
       "\n",
       "  CabinDeck CabinNumber CabinSide FirstName     LastName    Bills GroupSize  \n",
       "0         B           0         P     Maham    Ofracculy      0.0         1  \n",
       "1         F           0         S    Juanna        Vines    736.0         1  \n",
       "2         A           0         S    Altark       Susent  10383.0         2  \n",
       "3         A           0         S     Solam       Susent   5176.0         2  \n",
       "4         F           1         S     Willy  Santantines   1091.0         1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to impute attributes based on shared features\n",
    "def impute_attribute_by_shared_features(dataframe, attribute, shared_feature):\n",
    "    # Iterate through rows with missing values for the specified attribute\n",
    "    for index, row in dataframe[dataframe[attribute].isna()].iterrows():\n",
    "        # Find rows that share the specified feature and have known values for the attribute\n",
    "        rows_with_shared_features = dataframe[dataframe[shared_feature] == row[shared_feature]].dropna(subset=[attribute])\n",
    "        \n",
    "        # Impute the attribute if there are rows with shared features and known values\n",
    "        if not rows_with_shared_features.empty:\n",
    "            dataframe.loc[index, attribute] = rows_with_shared_features[attribute].iloc[0]\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "# Impute missing HomePlanet values based on shared group or last name\n",
    "df = impute_attribute_by_shared_features(df, 'HomePlanet', 'Group')\n",
    "df = impute_attribute_by_shared_features(df, 'HomePlanet', 'LastName')\n",
    "\n",
    "# Display the first few rows of the dataframe with imputed HomePlanet values\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Potential Cabin Decks and Sides\n",
    "\n",
    "For passengers with missing Cabin values, we can limit their options by excluding certain cabin decks or sides based on their attributes. This step is crucial for our structured imputation process. Specifically:\n",
    "\n",
    "1. **Home Planet Deck Restrictions**: Each home planet restricts passengers to certain decks. Additionally, if a passenger has no bills and their group members are on multiple decks, their deck is further restricted based on their home planet (Appendix B).\n",
    "2. **Group Cabin Side Consistency**: Every group is restricted to a single cabin side, even if they are split into multiple cabins (Appendix A.1).\n",
    "\n",
    "We define functions to add columns for potential decks and sides for passengers with missing Cabin values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to add a column for potential decks based on home planet and other conditions\n",
    "def add_potential_decks_column(dataframe):\n",
    "    # Define potential decks for each home planet\n",
    "    potential_decks_by_homeplanet = {\n",
    "        'Earth': ['E', 'F', 'G'],\n",
    "        'Europa': ['A', 'B', 'C', 'D', 'E', 'T'],\n",
    "        'Mars': ['D', 'E', 'F']\n",
    "    }\n",
    "\n",
    "    # Define restricted decks for passengers with no bills\n",
    "    potential_decks_by_homeplanet_no_bills = {\n",
    "        'Earth': ['G'],\n",
    "        'Europa': ['B'],\n",
    "        'Mars': ['E', 'F']\n",
    "    }\n",
    "    \n",
    "    # Inner function to determine potential decks for each passenger\n",
    "    def func_potential_decks_apply(row):\n",
    "        # If the Cabin value is missing\n",
    "        if pd.isna(row.Cabin):\n",
    "            # If the passenger has no bills, a known HomePlanet, and is part of a group\n",
    "            if row.Bills == 0 and not pd.isna(row.HomePlanet) and row.GroupSize > 1:\n",
    "                # Get the decks of other group members\n",
    "                group_members = dataframe[(dataframe.Group == row.Group) & (dataframe.PassengerId != row.PassengerId)].CabinDeck\n",
    "                \n",
    "                # If group members are in multiple different decks, restrict to specific decks for no bills\n",
    "                if group_members.dropna().nunique() > 1:\n",
    "                    return potential_decks_by_homeplanet_no_bills[row.HomePlanet]\n",
    "                \n",
    "                # If no group members have a known deck, return a combination of specific decks for no bills and known decks\n",
    "                elif not group_members.isna().any():\n",
    "                    return list(set(potential_decks_by_homeplanet_no_bills[row.HomePlanet] + list(group_members.dropna().unique())))\n",
    "                \n",
    "                # If group members are in one known deck, check if it matches the restricted decks\n",
    "                if group_members.nunique() == 1:\n",
    "                    if group_members.iloc[0] in potential_decks_by_homeplanet_no_bills[row.HomePlanet]:\n",
    "                        return potential_decks_by_homeplanet_no_bills[row.HomePlanet]\n",
    "            \n",
    "            # If the passenger has bills, return the standard decks for their HomePlanet\n",
    "            if not pd.isna(row.HomePlanet):\n",
    "                return potential_decks_by_homeplanet[row.HomePlanet]\n",
    "            \n",
    "            # If the HomePlanet is unknown, return all unique decks in the dataframe\n",
    "            else:\n",
    "                return list(dataframe.CabinDeck.dropna().unique())\n",
    "    \n",
    "    # Apply the inner function to each row in the dataframe\n",
    "    dataframe['PotentialDecks'] = dataframe.apply(func_potential_decks_apply, axis=1)\n",
    "    return dataframe\n",
    "\n",
    "# Define a function to add a column for potential sides based on group consistency\n",
    "def add_potential_sides_column(dataframe):\n",
    "    # Inner function to determine potential sides for each passenger\n",
    "    def func_potential_sides_apply(row):\n",
    "        # If the Cabin value is missing\n",
    "        if pd.isna(row.Cabin):\n",
    "            # Get the sides of other group members\n",
    "            group_sides = dataframe[dataframe.Group == row.Group].CabinSide.dropna()\n",
    "            \n",
    "            # If other group members have a known side, return that side\n",
    "            if group_sides.nunique() > 0:\n",
    "                return [group_sides.iloc[0]]\n",
    "            \n",
    "            # If no group members have a known side, return both possible sides\n",
    "            return ['P', 'S']\n",
    "        \n",
    "    # Apply the inner function to each row in the dataframe\n",
    "    dataframe['PotentialSides'] = dataframe.apply(func_potential_sides_apply, axis=1)\n",
    "    return dataframe\n",
    "\n",
    "# Apply the functions to add potential decks and sides columns\n",
    "df = add_potential_decks_column(df)\n",
    "df = add_potential_sides_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by Group and GroupNumber\n",
    "df = df.sort_values(by=['Group', 'GroupNumber'])\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding these columns, we can better manage the imputation of missing Cabin values by limiting the possible options based on the passenger's attributes and group dynamics.\n",
    "\n",
    "Sorting the dataframe by Group and GroupNumber is useful as it allows us to fill in free cabins in a logical order.\n",
    "\n",
    "With this preparation, we are now ready to proceed with the structured imputation of missing Cabin values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNumber</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Bills</th>\n",
       "      <th>GroupSize</th>\n",
       "      <th>PotentialDecks</th>\n",
       "      <th>PotentialSides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>Maham</td>\n",
       "      <td>Ofracculy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Juanna</td>\n",
       "      <td>Vines</td>\n",
       "      <td>736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Altark</td>\n",
       "      <td>Susent</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>02</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>Solam</td>\n",
       "      <td>Susent</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>Willy</td>\n",
       "      <td>Santantines</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall  ...  GroupNumber  CabinDeck  \\\n",
       "0          0.0        0.0           0.0  ...           01          B   \n",
       "1        109.0        9.0          25.0  ...           01          F   \n",
       "2         43.0     3576.0           0.0  ...           01          A   \n",
       "3          0.0     1283.0         371.0  ...           02          A   \n",
       "4        303.0       70.0         151.0  ...           01          F   \n",
       "\n",
       "  CabinNumber CabinSide FirstName     LastName    Bills GroupSize  \\\n",
       "0           0         P     Maham    Ofracculy      0.0         1   \n",
       "1           0         S    Juanna        Vines    736.0         1   \n",
       "2           0         S    Altark       Susent  10383.0         2   \n",
       "3           0         S     Solam       Susent   5176.0         2   \n",
       "4           1         S     Willy  Santantines   1091.0         1   \n",
       "\n",
       "   PotentialDecks PotentialSides  \n",
       "0            None           None  \n",
       "1            None           None  \n",
       "2            None           None  \n",
       "3            None           None  \n",
       "4            None           None  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataframe with potential decks and sides\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helpful function so that when we fill a cabin it'll fill the corresponding Deck, Number and Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_from_cabin_and_index(dataframe,cabin,index):\n",
    "    dataframe.loc[index,['Cabin','CabinDeck','CabinNumber','CabinSide']] = [cabin,cabin.split(\"/\")[0],int(cabin.split(\"/\")[1]),cabin.split(\"/\")[2]]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a major function finding all the passengers missing a cabin and collecting all the cabins it could potentially fill. This is conducted by looking athe potential decks and potential sides we've found, and seeing what room number of each of those decks and sides last came beforehand and first came afterwards.\n",
    "Ie if cabin A/02/S was before and A/03/S came after there is no room in between them for the passenger to fill, \n",
    "If however Cabin A/05/P came before them and A/07/P came after, then A/06/P is a cabin it could potentially take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passengers_empty_cabin_options(dataframe):\n",
    "    \n",
    "    df_passengers_without_cabin = dataframe[dataframe['Cabin'].isna()]\n",
    "    all_passenger_cabin_options = {}\n",
    "\n",
    "    for passenger_index, passenger in df_passengers_without_cabin.iterrows():\n",
    "        all_passenger_cabin_options[passenger_index] = []\n",
    "\n",
    "        for deck in passenger.PotentialDecks:\n",
    "            for side in passenger.PotentialSides:\n",
    "                \n",
    "                # Filter dataframe for the current deck and side\n",
    "                df_filtered = dataframe[(dataframe['CabinDeck'] == deck) & (dataframe['CabinSide'] == side)]\n",
    "\n",
    "                # Split into cabins before and after the current passenger index\n",
    "                max_cabin_no_before = max(df_filtered.loc[df_filtered.index < passenger_index, 'CabinNumber'].dropna().unique(), default = -1 )\n",
    "                min_cabin_no_after = min(df_filtered.loc[df_filtered.index > passenger_index, 'CabinNumber'].dropna().unique(), default = -1)\n",
    "\n",
    "                # If no cabins were found of that deck and side before or after the row\n",
    "                if max_cabin_no_before == -1 or min_cabin_no_after == -1:\n",
    "                    continue\n",
    "                \n",
    "                # If a cabin number is seen before the row and the next cabin number is more than 1 higher after the row\n",
    "                # then there is an empty cabin it can potentially fill\n",
    "                if max_cabin_no_before + 1 < min_cabin_no_after:\n",
    "                    all_passenger_cabin_options[passenger_index] += [f\"{deck}/{i}/{side}\" for i in range(max_cabin_no_before + 1, min_cabin_no_after)]\n",
    "\n",
    "    return all_passenger_cabin_options\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solo group and only one cabin that fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reasons we can't fill a cabin if the passenger has only one option of cabins from passengers_empty_cabin_options() is because the passenger also has an option to share a cabin. This function checks that they are alone in their group, meaning they can't share a cabin with anyone else as they can only share a cabin with a group member (Appendix A.6). If they are alone in their group and they have only one cabin option based on their position onboard then this cabin will be imputed for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solo_group_one_cabin_option(dataframe):\n",
    "    \n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "\n",
    "    # Iterates through all the passengers that haven't got a Cabin yet and are alone in their group (ie can't share)\n",
    "    for passenger_index in list(df[(df.Cabin.isna()) & (df.GroupSize == 1)].index):\n",
    "\n",
    "        # If they have only one free cabin that they could fill\n",
    "        if len(all_passenger_cabin_options[passenger_index]) == 1:\n",
    "            matching_cabin = all_passenger_cabin_options[passenger_index][0]\n",
    "            dataframe = impute_from_cabin_and_index(dataframe,matching_cabin,passenger_index)\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No free rooms so shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function imputes a cabin if they didn't have any empty cabin options, so will have to share a cabin with a member of their group. Some passengers have groups with multiple cabins, which we wouldn't want to guess which they would fit into, this problem can be eradicated if only one cabin that their group members are in meets their requirements we found in potential decks and potential sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_suitable_cabin_so_shares(dataframe):\n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "    \n",
    "    for passenger_index,passenger_cabin_options in all_passenger_cabin_options.items():\n",
    "        \n",
    "        # If there are no free cabins that the passenger can fill\n",
    "        if not passenger_cabin_options:\n",
    "            \n",
    "            passenger_row = dataframe.loc[passenger_index]\n",
    "            \n",
    "            # Finding all other group members cabins and filtering them by whether they are in the same deck that the passenger must be in\n",
    "            passengers_group_cabins = dataframe[(dataframe['Group'] == passenger_row['Group']) &\n",
    "                                  (dataframe['CabinDeck'].isin(passenger_row['PotentialDecks']))].Cabin.dropna()\n",
    "            \n",
    "            # If there is only one Cabin from their group they could share with\n",
    "            if passengers_group_cabins.nunique() == 1:\n",
    "                matching_cabin = passengers_group_cabins.iloc[0]\n",
    "                dataframe = impute_from_cabin_and_index(dataframe,matching_cabin,passenger_index)\n",
    "                \n",
    "    return dataframe\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only passenger that can take that cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final function works based on the presumption that every cabin is filled, (ie there are no gaps in the cabin numbers), if a passenger is the only passenger that suits a certain cabin then that passenger will have that cabin allocated to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_matching_passenger_for_cabin(dataframe):\n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "    \n",
    "    cabins_to_fill = defaultdict(list)\n",
    "    \n",
    "    # Iterate over cabins to see which passengers can fit that cabin\n",
    "    for passenger_index, cabin_options in all_passenger_cabin_options.items():\n",
    "        for cabin in cabin_options:\n",
    "            cabins_to_fill[cabin].append(passenger_index)\n",
    "    \n",
    "    # Iterate over cabin and impute passengers where only one fits\n",
    "    for cabin, passengers_indices in cabins_to_fill.items():\n",
    "        if len(passengers_indices) == 1:\n",
    "            dataframe = impute_from_cabin_and_index(dataframe, cabin, passengers_indices[0])\n",
    "    \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we impute some passengers with cabins, this limits the number of free cabins to the remaining passengers, it also reduces the competition to fill certain cabins, with my functions two iterations of them both fills all the cabins that the functions can find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def all_imputes(dataframe):\n",
    "    dataframe = solo_group_one_cabin_option(dataframe)\n",
    "    dataframe = no_suitable_cabin_so_shares(dataframe)\n",
    "    dataframe = only_matching_passenger_for_cabin(dataframe)\n",
    "\n",
    "    dataframe = solo_group_one_cabin_option(dataframe)\n",
    "    dataframe = no_suitable_cabin_so_shares(dataframe)\n",
    "    dataframe = only_matching_passenger_for_cabin(dataframe)\n",
    "    \n",
    "    return dataframe\n",
    "    \n",
    "df = all_imputes(df)\n",
    "df.Cabin.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 37 cabins that still remain unfilled, and we started with 299! There are still a few more that we can find that those functions did not cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual workings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function prints out some useful data to help us deduce some of the remaining cabins for ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_cabin_options_for_each_row(dataframe):\n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "    for passenger_index, passenger_options in all_passenger_cabin_options.items():\n",
    "        print()\n",
    "        print(\"PassengerId:\",dataframe.iloc[passenger_index].PassengerId, \"GroupSize:\", dataframe.iloc[passenger_index].GroupSize)\n",
    "        print(\"Free cabins that match:\")\n",
    "        print(passenger_options)\n",
    "\n",
    "                \n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PassengerId: 0293_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "\n",
      "PassengerId: 0310_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "\n",
      "PassengerId: 0348_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 0364_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 0374_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 1011_01 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/58/P']\n",
      "\n",
      "PassengerId: 1041_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S', 'E/58/P']\n",
      "\n",
      "PassengerId: 1095_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S']\n",
      "\n",
      "PassengerId: 1709_03 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 2092_03 GroupSize: 5\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 2513_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "\n",
      "PassengerId: 2514_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "\n",
      "PassengerId: 3034_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/98/P', 'B/99/P']\n",
      "\n",
      "PassengerId: 3053_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/98/P', 'B/99/P']\n",
      "\n",
      "PassengerId: 3287_02 GroupSize: 3\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 3411_02 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 3598_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "\n",
      "PassengerId: 3599_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "\n",
      "PassengerId: 4637_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/300/S', 'E/301/S']\n",
      "\n",
      "PassengerId: 4652_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/300/S', 'E/301/S']\n",
      "\n",
      "PassengerId: 6028_04 GroupSize: 5\n",
      "Free cabins that match:\n",
      "['D/191/P']\n",
      "\n",
      "PassengerId: 6048_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "\n",
      "PassengerId: 6060_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "\n",
      "PassengerId: 7182_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "\n",
      "PassengerId: 7183_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "\n",
      "PassengerId: 7353_03 GroupSize: 3\n",
      "Free cabins that match:\n",
      "['C/270/S']\n",
      "\n",
      "PassengerId: 7368_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/270/S', 'D/235/P']\n",
      "\n",
      "PassengerId: 7429_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/235/P', 'F/1424/S']\n",
      "\n",
      "PassengerId: 7440_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1424/S', 'G/1206/S']\n",
      "\n",
      "PassengerId: 7442_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['G/1206/S']\n",
      "\n",
      "PassengerId: 7463_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'F/1424/S', 'G/1212/S']\n",
      "\n",
      "PassengerId: 7469_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'G/1212/S']\n",
      "\n",
      "PassengerId: 7983_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "\n",
      "PassengerId: 7995_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "\n",
      "PassengerId: 8728_07 GroupSize: 8\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 9223_01 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['F/1785/S']\n",
      "\n",
      "PassengerId: 9223_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['F/1785/S']\n"
     ]
    }
   ],
   "source": [
    "all_cabin_options_for_each_row(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual imputation reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Passenger = 1011_01, Cabin = E/58/P\n",
    "  * Since the cabin can only be filled by 1011_01 and 1041_01, but one of 1041_01 and 1095_01 has to fill C/40/S and the other has to fill D/36/S as they are the only two that can fill C/40/S and D/36/S, it leaves passenger 1011_01 to fill E/58/P\n",
    "* Passenger = 3034_01,3053_01 , Cabin = B/98/P, B/99/P\n",
    "  * These indices weren't filled as the consecutive free cabins showed multiple options for each for those passengers, as no one else can fill it and index 3034_01 comes before 3053_01, they are filled in that order\n",
    "* Passenger = 4637_01,4652_01 , Cabin = E/300/S, E/301/S\n",
    "  * As with the previous example they are the only two passengers that can fill these cabins and didn't get imputed as the free cabins are consecutive\n",
    "* Passenger = 6028_04, Cabin = A/57/P\n",
    "  * As 6060_01 and 6048_01 are each alone in their groups and with only two cabins to fill, one of them must fill D/191/P and one must fill E/387/P leaving index 6028_04 no other option but to join the only cabin that the rest of its group is in.\n",
    "* Passenger 9223_01,9223_02 Cabin = F/1785/S, F/1785/S\n",
    "  * These two passengers are the only members of a group, they have one option for a cabin so they both must share F/1785/S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_list = [(1429,'E/58/P'),(4233,'B/98/P'),(4254,'B/99/P'),(6493,'E/300/S'),(6514,'E/301/S'),(8413,'A/57/P'), (12892,'F/1785/S'),(12893,'F/1785/S')]\n",
    "\n",
    "for index,cabin in cabin_list:\n",
    "    impute_from_cabin_and_index(df,cabin,index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Cabin.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have finished with all the cabins I can find that can be imputed, we have just but 29 Cabins remaining and should help all rise up the leaderboard!\n",
    "\n",
    "Below I will detail how we can split the data back into the training set and the test set, and then further detail the reasoning behind those last 29 passengers and why we can't decie which cabin they should take (yet). If any new inferences come to light please let me know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = df[df.Set == 'Train']\n",
    "testdata = df[df.Set == 'Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remaining Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PassengerId: 0293_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "\n",
      "PassengerId: 0310_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "\n",
      "PassengerId: 0348_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 0364_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 0374_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "\n",
      "PassengerId: 1041_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S']\n",
      "\n",
      "PassengerId: 1095_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S']\n",
      "\n",
      "PassengerId: 1709_03 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 2092_03 GroupSize: 5\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 2513_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "\n",
      "PassengerId: 2514_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "\n",
      "PassengerId: 3287_02 GroupSize: 3\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 3411_02 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "\n",
      "PassengerId: 3598_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "\n",
      "PassengerId: 3599_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "\n",
      "PassengerId: 6048_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "\n",
      "PassengerId: 6060_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "\n",
      "PassengerId: 7182_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "\n",
      "PassengerId: 7183_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "\n",
      "PassengerId: 7353_03 GroupSize: 3\n",
      "Free cabins that match:\n",
      "['C/270/S']\n",
      "\n",
      "PassengerId: 7368_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/270/S', 'D/235/P']\n",
      "\n",
      "PassengerId: 7429_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/235/P', 'F/1424/S']\n",
      "\n",
      "PassengerId: 7440_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1424/S', 'G/1206/S']\n",
      "\n",
      "PassengerId: 7442_02 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['G/1206/S']\n",
      "\n",
      "PassengerId: 7463_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'F/1424/S', 'G/1212/S']\n",
      "\n",
      "PassengerId: 7469_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'G/1212/S']\n",
      "\n",
      "PassengerId: 7983_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "\n",
      "PassengerId: 7995_01 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "\n",
      "PassengerId: 8728_07 GroupSize: 8\n",
      "Free cabins that match:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "all_cabin_options_for_each_row(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7442_02'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10411].PassengerId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cases of two passengers alone in their group and two cabins that fit both of their requirements**\n",
    "* Passenger 0293_01 and 0310_01, cabins B/13/P and C/13/S\n",
    "* Passenger 1041_01 and 1095_01, cabins C/40/S and D/36/S\n",
    "* Passenger 2513_01 and 2514_01, Cabins E/150/P and F/519/P\n",
    "* Passenger 3598_01 and 3599_01, Cabins G/590/P and G/579/S\n",
    "* Passenger 6048_01 and 6048_01, Cabins D/191/P and E/387/P\n",
    "* Passenger 7182_01 and 7183_01, Cabins F/1489/P and G/1157/P\n",
    "* Passenger 7463_01 and 7469_01, Cabins F/1544/P and G/1212/S *\n",
    "* Passenger 7983_01 and 7995_01, Cabins C/298/S and E/528/S\n",
    "\n",
    "\n",
    "* Passenger 7463_01 also has the option of  F/1424/S, but as 7463_01 and 7469_01 are the only passengers that can take F/1544/P and G/1212/S, logically 7463_01 must take one of (F/1554/P, G/1212/S) and 7469_01 must take the other\n",
    "\n",
    "\n",
    "**Cases of passengers who have to share a cabin with a member of their group, but there are multiple cabins that meet their requirements**\n",
    "* Passenger 1709_03, Cabins F/326/S, D/61/S, E/127/S\n",
    "* Passenger 2092_03, Cabins D/70/S, E/153/S, F/410/S\n",
    "* Passenger 3287_02, Cabins G/522/S, F/621/S\n",
    "* Passenger 3411_02, Cabins E/232/S, F/645/S\n",
    "* Passenger 8728_07, Cabins F/1798/P, G/1416/P\n",
    "\n",
    "**Other cases**\n",
    "* Each of the passengers 0348_02, 0364_02 and 0374_02 are in a group of 2 and are the only ones that can take cabins E/20/P and E/21/P, meaning that one of them shares with their group member and the other two take those cabins\n",
    "* Either 7353_03 takes cabin C/270/S and then 7368_01 takes D/235/P, 7429_01 takes F/1424/S, 7503_02 takes G/1206/S and 7442_02 shares E/495/S with a group member\n",
    "Or 7353_03 shares C/269/S with a group member, and then 7368_01 takes C/270/S, 7429_01 takes D/235/P, 7503_02 takes F/1424/S and 7442_02 takes G/1206/S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further assumptions,**\n",
    "There aren't more cabins available than we have assumed. While I was working on this project I had missed imputing lots of cabins as if a passenger was in a later group than the highest number on a given deck and side, there was the potential that the cabin numbers could go on past what we had seen. I had given up this belief when after assuming it didn't the passengers all fit in given the constraints that seemed unlikely if this wasnt the case. Ie by way of not finding any passengers that had no options or anyone to share with, nor rooms that had no passengers that could match them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_comp = pd.read_csv('data/31remaining.csv')\n",
    "df_to_comp = df_to_comp.rename(columns = {'Number':'CabinNumber'})\n",
    "df_to_comp['CabinNumber'] = df_to_comp['CabinNumber'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9267 G/1077/S F/1267/S\n",
      "12651 A/94/P nan\n",
      "12668 B/297/P nan\n"
     ]
    }
   ],
   "source": [
    "for index,row in df.iterrows():\n",
    "    if not (pd.isna(row.Cabin) and pd.isna(df_to_comp.iloc[index].Cabin)):\n",
    "        if row.Cabin != df_to_comp.iloc[index].Cabin:\n",
    "            print(index,row.Cabin, df_to_comp.iloc[index].Cabin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Evidence in the Appendix I will reuse the combined original dataframes without any imputations as to not misrepresent the underlying distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "df = pd.concat([training_data,test_data]) \n",
    "\n",
    "df = column_splits(df)\n",
    "df = df.sort_values(by = ['Group','GroupNumber'])\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of passengers sharing a group implying that their cabin is on the same side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with consistent cabin sides: 5825\n",
      "Number of rows with inconsistent cabin sides: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Group' and check if all non-NaN 'CabinSide' values within each group are the same\n",
    "consistent_count = 0\n",
    "inconsistent_count = 0\n",
    "\n",
    "# Iterate through each group\n",
    "for group, group_df in df.groupby('Group'):\n",
    "    if len(group_df) > 1:\n",
    "        # Get unique non-NaN CabinSide values\n",
    "        unique_sides = group_df['CabinSide'].dropna().unique()\n",
    "        \n",
    "        if len(unique_sides) <= 1:\n",
    "            # All rows in this group are consistent\n",
    "            consistent_count += len(group_df)\n",
    "        else:\n",
    "            # Some rows in this group are inconsistent\n",
    "            inconsistent_count += len(group_df)\n",
    "\n",
    "print(f\"Number of rows with consistent cabin sides: {consistent_count}\")\n",
    "print(f\"Number of rows with inconsistent cabin sides: {inconsistent_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of passengers sharing a group implying that they have the same home planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with consistent home planets: 5825\n",
      "Number of rows with inconsistent home planets: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "planet_consistent_count = 0\n",
    "planet_inconsistent_count = 0\n",
    "\n",
    "# Iterate through each group\n",
    "for group, group_df in df.groupby('Group'):\n",
    "    if len(group_df) > 1:\n",
    "    # Get unique non-NaN HomePlanet values\n",
    "        unique_home_planets = group_df['HomePlanet'].dropna().unique()\n",
    "        \n",
    "        if len(unique_home_planets) <= 1:\n",
    "            # All rows in this group are consistent in HomePlanet\n",
    "            planet_consistent_count += len(group_df)\n",
    "        else:\n",
    "            # Some rows in this group are inconsistent in HomePlanet\n",
    "            planet_inconsistent_count += len(group_df)\n",
    "\n",
    "print(f\"Number of rows with consistent home planets: {planet_consistent_count}\")\n",
    "print(f\"Number of rows with inconsistent home planets: {planet_inconsistent_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of passengers sharing a last name implying that they have the same home planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with consistent home planets by last name: 12468\n",
      "Number of rows with inconsistent home planets by last name: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "planet_consistent_count = 0\n",
    "planet_inconsistent_count = 0\n",
    "\n",
    "# Iterate through each last name group\n",
    "for last_name, group_df in df.groupby('LastName'):\n",
    "    if len(group_df) > 1:  # Exclude last names with only one passenger\n",
    "        # Get unique non-NaN HomePlanet values\n",
    "        unique_home_planets = group_df['HomePlanet'].dropna().unique()\n",
    "        \n",
    "        if len(unique_home_planets) <= 1:\n",
    "            # All rows in this group are consistent in HomePlanet\n",
    "            planet_consistent_count += len(group_df)\n",
    "        else:\n",
    "            # Some rows in this group are inconsistent in HomePlanet\n",
    "            planet_inconsistent_count += len(group_df)\n",
    "\n",
    "print(f\"Number of rows with consistent home planets by last name: {planet_consistent_count}\")\n",
    "print(f\"Number of rows with inconsistent home planets by last name: {planet_inconsistent_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of children under the age of 13 having no bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bills'] = df['RoomService'] + df['FoodCourt'] + df['ShoppingMall'] + df['Spa'] + df['VRDeck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for passengers under the age of 13 (excluding NaN Bills):\n",
      "   Total Under 13  Bills = 0  Bills != 0  Consistency Ratio\n",
      "0            1030       1030           0                1.0\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows with NaN values in Bills\n",
    "df_filtered = df[df['Bills'].notna()]\n",
    "\n",
    "# Check if passengers under the age of 13 have bills = 0\n",
    "under_13 = df_filtered[df_filtered['Age'] < 13]\n",
    "under_13_bills_zero = under_13['Bills'] == 0\n",
    "\n",
    "# Calculate summary statistics\n",
    "total_under_13 = len(under_13)\n",
    "bills_zero_under_13 = under_13_bills_zero.sum()\n",
    "bills_not_zero_under_13 = total_under_13 - bills_zero_under_13\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Total Under 13': [total_under_13],\n",
    "    'Bills = 0': [bills_zero_under_13],\n",
    "    'Bills != 0': [bills_not_zero_under_13],\n",
    "    'Consistency Ratio': [bills_zero_under_13 / total_under_13]\n",
    "})\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Summary statistics for passengers under the age of 13 (excluding NaN Bills):\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of those in CryoSleep having no bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for passengers under the age of 13 (excluding NaN Bills):\n",
      "   Total CryoSleep  Bills == 0  Bills != 0  Consistency Ratio\n",
      "0             4068        4068           0                1.0\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows with NaN values in Bills\n",
    "df_filtered = df[df['Bills'].notna()]\n",
    "\n",
    "# Check if passengers under the age of 13 have bills = 0\n",
    "cryo = df_filtered[df_filtered['CryoSleep'] == True]\n",
    "cryo_bills_zero = cryo['Bills'] == 0\n",
    "\n",
    "# Calculate summary statistics\n",
    "total_in_cryo = len(cryo)\n",
    "cryo_bills_zero = cryo_bills_zero.sum()\n",
    "cryo_bills_not_zero = total_in_cryo - cryo_bills_zero\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Total CryoSleep': [total_in_cryo],\n",
    "    'Bills == 0': [cryo_bills_zero],\n",
    "    'Bills != 0': [cryo_bills_not_zero],\n",
    "    'Consistency Ratio': [cryo_bills_zero / total_in_cryo]\n",
    "})\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Summary statistics for passengers under the age of 13 (excluding NaN Bills):\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabins shared by more than one group (with more than one member):\n",
      "Series([], Name: Group, dtype: object)\n",
      "\n",
      "Total multi-member cabins: 1684\n",
      "Multi-member cabins shared by multiple groups: 0\n",
      "Multi-member cabins unique to one group: 1684\n"
     ]
    }
   ],
   "source": [
    "# Filter cabins with more than one member\n",
    "cabin_counts = df['Cabin'].value_counts()\n",
    "multi_member_cabins = cabin_counts[cabin_counts > 1].index\n",
    "\n",
    "# Group by Cabin and list unique groups for each Cabin with more than one member\n",
    "cabin_group_mapping = df[df['Cabin'].isin(multi_member_cabins)].groupby('Cabin')['Group'].unique()\n",
    "\n",
    "# Check if any Cabin is associated with more than one group\n",
    "shared_cabins = cabin_group_mapping[cabin_group_mapping.apply(lambda groups: len(groups) > 1)]\n",
    "\n",
    "# Print the results\n",
    "print(\"Cabins shared by more than one group (with more than one member):\")\n",
    "print(shared_cabins)\n",
    "\n",
    "# Summary statistics\n",
    "total_multi_member_cabins = len(cabin_group_mapping)\n",
    "shared_cabin_count = len(shared_cabins)\n",
    "unique_cabin_count = total_multi_member_cabins - shared_cabin_count\n",
    "\n",
    "print(f\"\\nTotal multi-member cabins: {total_multi_member_cabins}\")\n",
    "print(f\"Multi-member cabins shared by multiple groups: {shared_cabin_count}\")\n",
    "print(f\"Multi-member cabins unique to one group: {unique_cabin_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of home planets restricting which deck a passenger's cabin is on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet  Earth  Europa  Mars\n",
      "CabinDeck                      \n",
      "A               0     346     0\n",
      "B               0    1124     0\n",
      "C               0    1081     0\n",
      "D               0     296   406\n",
      "E             583     197   508\n",
      "F            2426       0  1713\n",
      "G            3700       0     0\n",
      "T               0      10     0\n"
     ]
    }
   ],
   "source": [
    "# Group by 'HomePlanet' and 'CabinDeck' and count occurrences\n",
    "deck_counts = df.groupby(['HomePlanet', 'CabinDeck']).size().reset_index(name='Count')\n",
    "\n",
    "# Pivot the table to get a better overview\n",
    "pivot_table = deck_counts.pivot(index='CabinDeck', columns='HomePlanet', values='Count').fillna(0).astype(int)\n",
    "\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CabinDecks for passengers with bills = 0 in groups with multiple CabinDecks:\n",
      "HomePlanet: Earth\n",
      "  CabinDeck: G, Count: 526\n",
      "HomePlanet: Mars\n",
      "  CabinDeck: F, Count: 160\n",
      "  CabinDeck: E, Count: 47\n",
      "HomePlanet: Europa\n",
      "  CabinDeck: B, Count: 11\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Iterate through each group\n",
    "for group, group_df in df.groupby('Group'):\n",
    "    # Check if within the group there are more than one CabinDeck\n",
    "    unique_decks = group_df['CabinDeck'].dropna().unique()\n",
    "    \n",
    "    if len(unique_decks) > 1:\n",
    "        # Find passengers with bills = 0\n",
    "        zero_bill_passengers = group_df[(group_df['Bills'] == 0)  & (group_df['HomePlanet'].notna())]\n",
    "        \n",
    "        for idx, passenger in zero_bill_passengers.iterrows():\n",
    "            home_planet = passenger['HomePlanet']\n",
    "            cabin_deck = passenger['CabinDeck']\n",
    "            \n",
    "            if home_planet not in results:\n",
    "                results[home_planet] = []\n",
    "            \n",
    "            results[home_planet].append(cabin_deck)\n",
    "\n",
    "# Print the results\n",
    "print(\"CabinDecks for passengers with bills = 0 in groups with multiple CabinDecks:\")\n",
    "for home_planet, cabin_decks in results.items():\n",
    "    cabin_deck_counts = pd.Series(cabin_decks).value_counts().to_dict()\n",
    "    print(f\"HomePlanet: {home_planet}\")\n",
    "    for deck, count in cabin_deck_counts.items():\n",
    "        print(f\"  CabinDeck: {deck}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512\n",
      "1513\n",
      "2778\n",
      "7216\n"
     ]
    }
   ],
   "source": [
    "for index,row in df_to_comp.iterrows():\n",
    "    if row.HomePlanet == 'Earth':\n",
    "        if row.Deck == 'E':\n",
    "            if row.GroupSize == 2:\n",
    "                if row.Bills == 0:\n",
    "                    if df_to_comp[df_to_comp.Group == row.Group].Deck.nunique() == 1:\n",
    "                        print(index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spaceenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
