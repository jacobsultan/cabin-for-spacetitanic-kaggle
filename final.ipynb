{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change index for passenger ID and maybe get rid of iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following notebook I will show you the algorithmic approach I used to fill (nearly) every Cabin. This is not a guessing/probabilistic approach, cabins are filled in a structured order based on the passengers Homeplanet and its group (from its passengerID).\n",
    "\n",
    "Cabins are filled in order based on their number, ie if a passenger is in cabin A/05/P, a passenger in a later group cannot be in A/04/P but they could be in A/01/S, or B/01/P\n",
    "\n",
    "We are defining the components of the cabin by \n",
    "A/01/P\n",
    "A = cabin deck, can take values 'A','B','C','D','E','F','G','T'\n",
    "01 = cabin number, can take values 0,1,2...\n",
    "P  = cabin side, can take values 'P', 'S' (presumably 'Port' and 'Starboard' )\n",
    "\n",
    "Some assumptions\n",
    "* If two passengers are in the same group then they are on the same side, Appendix A.1\n",
    "* If two passengers are in the same group then they are from the same home planet, Appendix A.2\n",
    "* If two passengers share a last name then they are from the same home planet, Appendix A.3\n",
    "* Children <= 12 in age have no bills, Appendix A.4\n",
    "* Those who have Cryosleep = True have no bills, Appendix A.5\n",
    "* Cabins can only be shared with group members, Appendix A.6\n",
    "* Home planets restrict which decks a passenger is on, Appendix B\n",
    "** Passengers with Mars as their home planet are in decks 'D','E' or 'F'\n",
    "** Passengers with Earth as their home planet are in decks 'E','F' or 'G'\n",
    "** Passengers with Europa as their home planet are in decks 'A','B','C','D','E','T'\n",
    "** If a passenger has no bills (RoomService + ShoppingMall + Spa + VRDeck + FoodCourt) and has members in its group in different decks then they are restricted to these decks \n",
    "*** Earth :'G'\n",
    "*** Europa: 'B'\n",
    "*** Mars: 'E','F'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we combine the training data and the test data as their orders by group are preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from collections import defaultdict # Slightly modified from a regular dictionary\n",
    "\n",
    "\n",
    "training_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "training_data['Set'] = 'Train'\n",
    "test_data['Set'] = 'Test'\n",
    "\n",
    "# The combined dataframe we will be using for the rest of this project\n",
    "df = pd.concat([training_data,test_data]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our starting point, we have 299 Cabins that are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cabin'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split their unique PassengerId into Group and their number in the group,\n",
    "we split their cabin into the deck,side and number and we split their names into first and last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_splits(data_frame):\n",
    "    data_frame[['Group', 'GroupNumber']] = data_frame['PassengerId'].str.split('_', expand=True)\n",
    "\n",
    "    data_frame[['CabinDeck', 'CabinNumber', 'CabinSide']]= data_frame['Cabin'].str.split(\"/\", expand = True)\n",
    "    data_frame.CabinNumber = data_frame.CabinNumber.astype('Int64')\n",
    "    \n",
    "    data_frame[['FirstName','LastName']] = data_frame['Name'].str.split(\" \",expand = True)\n",
    "\n",
    "    return data_frame\n",
    "\n",
    "df = column_splits(df)\n",
    "\n",
    "\n",
    "df = df.sort_values(by = ['Group','GroupNumber'])\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total bills are composed of the summation of each passengers roomservice, foodcourt, shoppingmall, spa and vrdeck payments.\n",
    "We can impute bills to be equal to 0 if someone is under 13 and/or they are in cryosleep (Appendix A.4,A.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bills'] = df['RoomService'] + df['FoodCourt'] + df['ShoppingMall'] + df['Spa'] + df['VRDeck']\n",
    "df.loc[(df['Age'] < 13), 'Bills'] = 0\n",
    "df.loc[(df['CryoSleep'] == True),'Bills'] = 0 \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Size is a useful column seeing how many passengers are in their group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_group_size_column(dataframe):\n",
    "    dataframe['GroupSize'] = dataframe.groupby('Group')['Group'].transform('count')\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "df = add_group_size_column(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function to impute attributes based on a shared feature, rows with missing values for their homeplanet will be imputed if they share a group with someone else with their homeplanet known or share a last name (Appendix A.2,A.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_attribute_by_shared_features(dataframe,attribute,shared_feature):\n",
    "    \n",
    "    # Iterates through all the rows that have nan for this attribute\n",
    "    for index, row in dataframe[dataframe[attribute].isna()].iterrows():\n",
    "        rows_with_shared_features = dataframe[dataframe[shared_feature] == row[shared_feature]].dropna(subset=[attribute])\n",
    "        \n",
    "        if not rows_with_shared_features.empty:\n",
    "            dataframe.loc[index, attribute] = rows_with_shared_features[attribute].iloc[0]\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "df = impute_attribute_by_shared_features(df,'HomePlanet','Group')\n",
    "df = impute_attribute_by_shared_features(df,'HomePlanet','LastName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who have missing Cabin values, we can limit their options by removing some cabin decks or sides that they can fit into. We know that some homeplanets can only be on some decks and that if a passenger has bills = 0 and their group are in multiple decks then they must be in a certain deck based on their home planet (Appendix B).\n",
    "\n",
    "We also know that every group is only on one cabin side even if the group is split into multiple Cabins (Appendix A.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_potential_decks_column(dataframe):\n",
    "    \n",
    "    potential_decks_by_homeplanet = {\n",
    "    'Earth':['E','F','G'],\n",
    "    'Europa': ['A','B','C','D','E','T'],\n",
    "    'Mars': ['D','E','F']\n",
    "    }\n",
    "\n",
    "    potential_decks_by_homeplanet_no_bills = {\n",
    "        'Earth':['G'],\n",
    "        'Europa':['B'],\n",
    "        'Mars': ['E','F']\n",
    "    }\n",
    "    \n",
    "    def func_potential_decks_apply(row):\n",
    "        if pd.isna(row.Cabin):\n",
    "            if row.Bills == 0 and not pd.isna(row.HomePlanet) and row.GroupSize > 1:\n",
    "                \n",
    "                group_members = dataframe[(dataframe.Group == row.Group) & (dataframe.PassengerId != row.PassengerId)].CabinDeck\n",
    "                # Checking if other members of group are in multiple different cabin decks\n",
    "                if group_members.dropna().nunique() > 1:\n",
    "                    return potential_decks_by_homeplanet_no_bills[row.HomePlanet]\n",
    "                \n",
    "                elif not group_members.isna().any():\n",
    "                    return list(set(potential_decks_by_homeplanet_no_bills[row.HomePlanet] + list(group_members.dropna().unique())))\n",
    "\n",
    "                if group_members.nunique() == 1:\n",
    "                    if group_members.iloc[0] in potential_decks_by_homeplanet_no_bills[row.HomePlanet]:\n",
    "                        return potential_decks_by_homeplanet_no_bills[row.HomePlanet]\n",
    "                    \n",
    "            # If there bills are greater than 0 then it goes to the standard decks for their homeplanet\n",
    "            if not pd.isna(row.HomePlanet):\n",
    "                return potential_decks_by_homeplanet[row.HomePlanet]\n",
    "            \n",
    "            # If their homeplanet isn't known then they could be in any cabin deck\n",
    "            else:\n",
    "                return list(dataframe.CabinDeck.dropna().unique())\n",
    "            \n",
    "    dataframe['PotentialDecks'] = dataframe.apply(func_potential_decks_apply,axis = 1)\n",
    "    return dataframe\n",
    "    \n",
    "            \n",
    "\n",
    "def add_potential_sides_column(dataframe):\n",
    "    \n",
    "    def func_potential_sides_apply(row):\n",
    "        if pd.isna(row.Cabin):\n",
    "            \n",
    "            # Checks to see if anyone else in their group has a known cabin side\n",
    "            group_sides = dataframe[dataframe.Group == row.Group].CabinSide.dropna()\n",
    "            if group_sides.nunique() > 0:\n",
    "                return [group_sides.iloc[0]]\n",
    "            \n",
    "            # If no one else is in their group or they haven't got a known cabin side then the passenger could be on either side\n",
    "            return ['P','S']\n",
    "        \n",
    "    dataframe['PotentialSides'] = dataframe.apply(func_potential_sides_apply,axis = 1)\n",
    "    return dataframe\n",
    "\n",
    "    \n",
    "df = add_potential_decks_column(df)\n",
    "df = add_potential_sides_column(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordering the values by Group then GroupNumber will be useful as this is the order we can fill up free cabins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by = ['Group','GroupNumber'])\n",
    "df = df.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helpful function so that when we fill a cabin it'll fill the corresponding Deck, Number and Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_from_cabin_and_index(dataframe,cabin,index):\n",
    "    dataframe.loc[index,['Cabin','CabinDeck','CabinNumber','CabinSide']] = [cabin,cabin.split(\"/\")[0],int(cabin.split(\"/\")[1]),cabin.split(\"/\")[2]]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a major function finding all the passengers missing a cabin and collecting all the cabins it could potentially fill. This is conducted by looking athe potential decks and potential sides we've found, and seeing what room number of each of those decks and sides last came beforehand and first came afterwards.\n",
    "Ie if cabin A/02/S was before and A/03/S came after there is no room in between them for the passenger to fill, \n",
    "If however Cabin A/05/P came before them and A/07/P came after, then A/06/P is a cabin it could potentially take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passengers_empty_cabin_options(dataframe):\n",
    "    \n",
    "    df_passengers_without_cabin = dataframe[dataframe['Cabin'].isna()]\n",
    "    all_passenger_cabin_options = {}\n",
    "\n",
    "    for passenger_index, passenger in df_passengers_without_cabin.iterrows():\n",
    "        all_passenger_cabin_options[passenger_index] = []\n",
    "\n",
    "        for deck in passenger.PotentialDecks:\n",
    "            for side in passenger.PotentialSides:\n",
    "                \n",
    "                # Filter dataframe for the current deck and side\n",
    "                df_filtered = dataframe[(dataframe['CabinDeck'] == deck) & (dataframe['CabinSide'] == side)]\n",
    "\n",
    "                # Split into cabins before and after the current passenger index\n",
    "                max_cabin_no_before = max(df_filtered.loc[df_filtered.index < passenger_index, 'CabinNumber'].dropna().unique(), default = -1 )\n",
    "                min_cabin_no_after = min(df_filtered.loc[df_filtered.index > passenger_index, 'CabinNumber'].dropna().unique(), default = -1)\n",
    "\n",
    "                # If no cabins were found of that deck and side before or after the row\n",
    "                if max_cabin_no_before == -1 or min_cabin_no_after == -1:\n",
    "                    continue\n",
    "                \n",
    "                # If a cabin number is seen before the row and the next cabin number is more than 1 higher after the row\n",
    "                # then there is an empty cabin it can potentially fill\n",
    "                if max_cabin_no_before + 1 < min_cabin_no_after:\n",
    "                    all_passenger_cabin_options[passenger_index] += [f\"{deck}/{i}/{side}\" for i in range(max_cabin_no_before + 1, min_cabin_no_after)]\n",
    "\n",
    "    return all_passenger_cabin_options\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solo group and only one room that fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reasons we can't fill a cabin if the passenger has only one option of cabins from passengers_empty_cabin_options() is because the passenger also has an option to share a cabin. This function checks that they are alone in their group, meaning they can't share a cabin with anyone else as they can only share a cabin with a group member (Appendix A.6). If they are alone in their group and they have only one cabin option based on their position onboard then this cabin will be imputed for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solo_group_one_cabin_option(dataframe):\n",
    "    \n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "\n",
    "    # Iterates through all the passengers that haven't got a Cabin yet and are alone in their group (ie can't share)\n",
    "    for passenger_index in list(df[(df.Cabin.isna()) & (df.GroupSize == 1)].index):\n",
    "\n",
    "        # If they have only one free cabin that they could fill\n",
    "        if len(all_passenger_cabin_options[passenger_index]) == 1:\n",
    "            matching_cabin = all_passenger_cabin_options[passenger_index][0]\n",
    "            dataframe = impute_from_cabin_and_index(dataframe,matching_cabin,passenger_index)\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no free rooms so has to share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function imputes a cabin if they didn't have any empty cabin options, so will have to share a cabin with a member of their group. Some passengers have groups with multiple cabins, which we wouldn't want to guess which they would fit into, this problem can be eradicated if only one cabin that their group members are in meets their requirements we found in potential decks and potential sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_suitable_cabin_so_shares(dataframe):\n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "    \n",
    "    for passenger_index,passenger_cabin_options in all_passenger_cabin_options.items():\n",
    "        \n",
    "        # If there are no free cabins that the passenger can fill\n",
    "        if not passenger_cabin_options:\n",
    "            \n",
    "            passenger_row = dataframe.loc[passenger_index]\n",
    "            \n",
    "            # Finding all other group members cabins and filtering them by whether they are in the same deck that the passenger must be in\n",
    "            passengers_group_cabins = dataframe[(dataframe['Group'] == passenger_row['Group']) &\n",
    "                                  (dataframe['CabinDeck'].isin(passenger_row['PotentialDecks']))].Cabin.dropna()\n",
    "            \n",
    "            # If there is only one Cabin from their group they could share with\n",
    "            if passengers_group_cabins.nunique() == 1:\n",
    "                matching_cabin = passengers_group_cabins.iloc[0]\n",
    "                dataframe = impute_from_cabin_and_index(dataframe,matching_cabin,passenger_index)\n",
    "                \n",
    "    return dataframe\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only passenger that can take that cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final function works based on the presumption that every cabin is filled, (ie there are no gaps in the cabin numbers), if a passenger is the only passenger that suits a certain cabin then that passenger will have that cabin allocated to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_matching_passenger_for_cabin(dataframe):\n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "    \n",
    "    cabins_to_fill = defaultdict(list)\n",
    "    \n",
    "    # Iterate over cabins to see which passengers can fit that cabin\n",
    "    for passenger_index, cabin_options in all_passenger_cabin_options.items():\n",
    "        for cabin in cabin_options:\n",
    "            cabins_to_fill[cabin].append(passenger_index)\n",
    "    \n",
    "    # Iterate over cabin and impute passengers where only one fits\n",
    "    for cabin, passengers_indices in cabins_to_fill.items():\n",
    "        if len(passengers_indices) == 1:\n",
    "            dataframe = impute_from_cabin_and_index(dataframe, cabin, passengers_indices[0])\n",
    "    \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all imputes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we impute some passengers with cabins, this limits the number of free cabins to the remaining passengers, it also reduces the competition to fill certain cabins, with my functions two iterations of them both fills all the cabins that the functions can find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def all_imputes(dataframe):\n",
    "    dataframe = solo_group_one_cabin_option(dataframe)\n",
    "    dataframe = no_suitable_cabin_so_shares(dataframe)\n",
    "    dataframe = only_matching_passenger_for_cabin(dataframe)\n",
    "\n",
    "    dataframe = solo_group_one_cabin_option(dataframe)\n",
    "    dataframe = no_suitable_cabin_so_shares(dataframe)\n",
    "    dataframe = only_matching_passenger_for_cabin(dataframe)\n",
    "    \n",
    "    return dataframe\n",
    "    \n",
    "df = all_imputes(df)\n",
    "df.Cabin.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 37 cabins that still remain unfilled, and we started with 299! There are still a few more that we can find that those functions did not cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual workings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function prints out some useful data to help us deduce some of the remaining cabins for ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_cabin_options_for_each_row(dataframe):\n",
    "    all_passenger_cabin_options = passengers_empty_cabin_options(dataframe)\n",
    "    for passenger_index, passenger_options in all_passenger_cabin_options.items():\n",
    "        print()\n",
    "        print(\"Index:\",passenger_index, \"GroupSize:\", dataframe.iloc[passenger_index].GroupSize)\n",
    "        print(\"Free cabins that match:\")\n",
    "        print(passenger_options)\n",
    "\n",
    "                \n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index: 404 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "0.0\n",
      "\n",
      "Index: 421 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "nan\n",
      "\n",
      "Index: 479 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "2385.0\n",
      "\n",
      "Index: 505 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "1298.0\n",
      "\n",
      "Index: 517 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "789.0\n",
      "\n",
      "Index: 1429 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/58/P']\n",
      "1692.0\n",
      "\n",
      "Index: 1466 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S', 'E/58/P']\n",
      "0.0\n",
      "\n",
      "Index: 1543 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S']\n",
      "0.0\n",
      "\n",
      "Index: 2442 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "1338.0\n",
      "\n",
      "Index: 2970 GroupSize: 5\n",
      "Free cabins that match:\n",
      "[]\n",
      "9597.0\n",
      "\n",
      "Index: 3529 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "711.0\n",
      "\n",
      "Index: 3530 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "791.0\n",
      "\n",
      "Index: 4233 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/98/P', 'B/99/P']\n",
      "0.0\n",
      "\n",
      "Index: 4254 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/98/P', 'B/99/P']\n",
      "11788.0\n",
      "\n",
      "Index: 4569 GroupSize: 3\n",
      "Free cabins that match:\n",
      "[]\n",
      "770.0\n",
      "\n",
      "Index: 4751 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "3674.0\n",
      "\n",
      "Index: 5016 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "676.0\n",
      "\n",
      "Index: 5017 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "908.0\n",
      "\n",
      "Index: 6493 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/300/S', 'E/301/S']\n",
      "nan\n",
      "\n",
      "Index: 6514 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/300/S', 'E/301/S']\n",
      "997.0\n",
      "\n",
      "Index: 8413 GroupSize: 5\n",
      "Free cabins that match:\n",
      "['D/191/P']\n",
      "4681.0\n",
      "\n",
      "Index: 8450 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "0.0\n",
      "\n",
      "Index: 8465 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "nan\n",
      "\n",
      "Index: 10081 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "2020.0\n",
      "\n",
      "Index: 10082 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "0.0\n",
      "\n",
      "Index: 10290 GroupSize: 3\n",
      "Free cabins that match:\n",
      "['C/270/S']\n",
      "4093.0\n",
      "\n",
      "Index: 10313 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/270/S', 'D/235/P']\n",
      "0.0\n",
      "\n",
      "Index: 10394 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/235/P', 'F/1424/S']\n",
      "1183.0\n",
      "\n",
      "Index: 10408 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1424/S', 'G/1206/S']\n",
      "898.0\n",
      "\n",
      "Index: 10411 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['G/1206/S']\n",
      "0.0\n",
      "\n",
      "Index: 10434 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'F/1424/S', 'G/1212/S']\n",
      "677.0\n",
      "\n",
      "Index: 10440 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'G/1212/S']\n",
      "775.0\n",
      "\n",
      "Index: 11129 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "0.0\n",
      "\n",
      "Index: 11148 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "0.0\n",
      "\n",
      "Index: 12174 GroupSize: 8\n",
      "Free cabins that match:\n",
      "[]\n",
      "1019.0\n",
      "\n",
      "Index: 12892 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['F/1785/S']\n",
      "0.0\n",
      "\n",
      "Index: 12893 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['F/1785/S']\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "all_cabin_options_for_each_row(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual imputation reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Index = 1429, Cabin = E/58/P\n",
    "** Since the cabin can only be filled by 1429 and 1466, but one of 1466 and 1543 has to fill C/40/S and the other has to fill D/36/S as the only two that can fill those two, it leaves index 1429 to fill E/58/P\n",
    "* Index = 4233,4254 , Cabin = B/98/P, B/99/P\n",
    "** These indices weren't filled as the consecutive free cabins showed multiple options for each for those passengers, as no one else can fill it and index 4233 comes before 4254, they are filled in that order\n",
    "* Index = 6493,6514 , Cabin = E/300/S, E/301/S\n",
    "** As with the previous example they are the only two cabins that can fill these cabins and didn't get imputed as the free cabins are consecutive\n",
    "* Index = 8413, Cabin = A/57/P\n",
    "** As index 8465 and 8450 are each alone in their groups and with only two cabins to fill, one of them must fill D/191/P and one must fill E/387/P leaving index 8413 no other option but to join the only cabin that the rest of its group is in.\n",
    "* Index 12892,12893 Cabin = F/1785/S, F/1785/S\n",
    "** These two indices are the only members of a group together, they have one option for a cabin so they must both share F/1785/S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "cabin_list = [(1429,'E/58/P'),(4233,'B/98/P'),(4254,'B/99/P'),(6493,'E/300/S'),(6514,'E/301/S'),(8413,'A/57/P'), (12892,'F/1785/S'),(12893,'F/1785/S')]\n",
    "\n",
    "for index,cabin in cabin_list:\n",
    "    impute_from_cabin_and_index(df,cabin,index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Cabin.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have finished with all the cabins I can find that can be imputed, we have just but 29 Cabins remaining and should help all rise up the leaderboard!\n",
    "\n",
    "Below I will detail how we can split the data back into the training set and the test set, and then further detail the reasoning behind those last 29 passengers and why we can't decie which cabin they should take (yet). If any new inferences come to light please let me know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = df[df.Set == 'Train']\n",
    "testdata = df[df.Set == 'Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remaining Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index: 404 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "0.0\n",
      "\n",
      "Index: 421 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['B/13/P', 'C/13/S']\n",
      "nan\n",
      "\n",
      "Index: 479 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "2385.0\n",
      "\n",
      "Index: 505 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "1298.0\n",
      "\n",
      "Index: 517 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['E/20/P', 'E/21/P']\n",
      "789.0\n",
      "\n",
      "Index: 1466 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S']\n",
      "0.0\n",
      "\n",
      "Index: 1543 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/40/S', 'D/36/S']\n",
      "0.0\n",
      "\n",
      "Index: 2442 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "1338.0\n",
      "\n",
      "Index: 2970 GroupSize: 5\n",
      "Free cabins that match:\n",
      "[]\n",
      "9597.0\n",
      "\n",
      "Index: 3529 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "711.0\n",
      "\n",
      "Index: 3530 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['E/150/P', 'F/519/P']\n",
      "791.0\n",
      "\n",
      "Index: 4569 GroupSize: 3\n",
      "Free cabins that match:\n",
      "[]\n",
      "770.0\n",
      "\n",
      "Index: 4751 GroupSize: 7\n",
      "Free cabins that match:\n",
      "[]\n",
      "3674.0\n",
      "\n",
      "Index: 5016 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "676.0\n",
      "\n",
      "Index: 5017 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['G/590/P', 'G/579/S']\n",
      "908.0\n",
      "\n",
      "Index: 8450 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "0.0\n",
      "\n",
      "Index: 8465 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/191/P', 'E/387/P']\n",
      "nan\n",
      "\n",
      "Index: 10081 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "2020.0\n",
      "\n",
      "Index: 10082 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1489/P', 'G/1157/P']\n",
      "0.0\n",
      "\n",
      "Index: 10290 GroupSize: 3\n",
      "Free cabins that match:\n",
      "['C/270/S']\n",
      "4093.0\n",
      "\n",
      "Index: 10313 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/270/S', 'D/235/P']\n",
      "0.0\n",
      "\n",
      "Index: 10394 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['D/235/P', 'F/1424/S']\n",
      "1183.0\n",
      "\n",
      "Index: 10408 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1424/S', 'G/1206/S']\n",
      "898.0\n",
      "\n",
      "Index: 10411 GroupSize: 2\n",
      "Free cabins that match:\n",
      "['G/1206/S']\n",
      "0.0\n",
      "\n",
      "Index: 10434 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'F/1424/S', 'G/1212/S']\n",
      "677.0\n",
      "\n",
      "Index: 10440 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['F/1544/P', 'G/1212/S']\n",
      "775.0\n",
      "\n",
      "Index: 11129 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "0.0\n",
      "\n",
      "Index: 11148 GroupSize: 1\n",
      "Free cabins that match:\n",
      "['C/298/S', 'E/528/S']\n",
      "0.0\n",
      "\n",
      "Index: 12174 GroupSize: 8\n",
      "Free cabins that match:\n",
      "[]\n",
      "1019.0\n"
     ]
    }
   ],
   "source": [
    "all_cabin_options_for_each_row(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cases of two passengers alone in their group and two cabins that fit both of their requirements\n",
    "* Index 404 and 421, cabins B/13/P and C/13/S\n",
    "* index 1466 and 1543, cabins C/40/S and D/36/S\n",
    "* Index 3529 and 3530, Cabins E/150/P and F/519/P\n",
    "* Index 5016 and 5017, Cabins G/590/P and G/579/S\n",
    "* Index 8450 and 8465, Cabins D/191/P and E/387/P\n",
    "* Index 10081 and 10082, Cabins F/1489/P and G/1157/P\n",
    "* Index 10434 and 10440, Cabins F/1544/P and G/1212/S **\n",
    "* Index 11129 and 11148, Cabins C/298/S and E/528/S\n",
    "** Index 10434 has the option of  F/1424/S but as 10434 and 10440 are the only passengers that can take F/1544/P and G/1212/S one must logically take one of each\n",
    "\n",
    "\n",
    "Cases of passengers who have to share a cabin with a member of their group, but there are multiple cabins that meet their requirements\n",
    "* Index 2442, Cabins F/326/S, D/61/S, E/127/S\n",
    "* Index 2970, Cabins D/70/S, E/153/S, F/410/S\n",
    "* Index 4569, Cabins G/522/S, F/621/S\n",
    "* Index 4751, Cabins E/232/S, F/645/S\n",
    "* Index 12174, Cabins F/1798/P, G/1416/P\n",
    "\n",
    "Other cases\n",
    "* Each of index 479, 505 and 517 are in a group of 2 and are the only ones that can take cabins E/20/P and E/21/P, meaning that one of them shares with their group member and the other two take those cabins\n",
    "* Either 10290 takes cabin C/270/S and then 10313 takes D/235/P, 10394 takes F/1424/S, 10408 takes G/1206/S and 10411 shares E/495/S\n",
    "Or 10290 shares C/269/S and then 10313 takes C/270/S, 10394 takes D/235/P, 10408 takes F/1424/S and 10411 takes G/1206/S\n",
    "* 10290 10313 10394 10408 10411 10434 10440 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further assumptions,\n",
    "There aren't more cabins available than we have assumed. While I was working on this project I had missed imputing lots of cabins as if a passenger was in a later group than the highest number on a given deck and side, there was the potential that the cabin numbers could go on past what we had seen. I had given up this belief when after assuming it didn't the passengers all fit in given the constraints that seemed unlikely if this wasnt the case. Ie by way of not finding any passengers that had no options or anyone to share with, nor rooms that had no passengers that could match them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Evidence in the Appendix I will reuse the combined original dataframes without any imputations as to not misrepresent the underlying distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "df = pd.concat([training_data,test_data]) \n",
    "\n",
    "df = column_splits(df)\n",
    "df = df.sort_values(by = ['Group','GroupNumber'])\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of passengers sharing a group implying that their cabin is on the same side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with consistent cabin sides: 5825\n",
      "Number of rows with inconsistent cabin sides: 0\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Group' and check if all non-NaN 'CabinSide' values within each group are the same\n",
    "consistent_count = 0\n",
    "inconsistent_count = 0\n",
    "\n",
    "# Iterate through each group\n",
    "for group, group_df in df.groupby('Group'):\n",
    "    if len(group_df) > 1:\n",
    "        # Get unique non-NaN CabinSide values\n",
    "        unique_sides = group_df['CabinSide'].dropna().unique()\n",
    "        \n",
    "        if len(unique_sides) <= 1:\n",
    "            # All rows in this group are consistent\n",
    "            consistent_count += len(group_df)\n",
    "        else:\n",
    "            # Some rows in this group are inconsistent\n",
    "            inconsistent_count += len(group_df)\n",
    "\n",
    "print(f\"Number of rows with consistent cabin sides: {consistent_count}\")\n",
    "print(f\"Number of rows with inconsistent cabin sides: {inconsistent_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of passengers sharing a group implying that they have the same home planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with consistent home planets: 5825\n",
      "Number of rows with inconsistent home planets: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "planet_consistent_count = 0\n",
    "planet_inconsistent_count = 0\n",
    "\n",
    "# Iterate through each group\n",
    "for group, group_df in df.groupby('Group'):\n",
    "    if len(group_df) > 1:\n",
    "    # Get unique non-NaN HomePlanet values\n",
    "        unique_home_planets = group_df['HomePlanet'].dropna().unique()\n",
    "        \n",
    "        if len(unique_home_planets) <= 1:\n",
    "            # All rows in this group are consistent in HomePlanet\n",
    "            planet_consistent_count += len(group_df)\n",
    "        else:\n",
    "            # Some rows in this group are inconsistent in HomePlanet\n",
    "            planet_inconsistent_count += len(group_df)\n",
    "\n",
    "print(f\"Number of rows with consistent home planets: {planet_consistent_count}\")\n",
    "print(f\"Number of rows with inconsistent home planets: {planet_inconsistent_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of passengers sharing a last name implying that they have the same home planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with consistent home planets by last name: 12468\n",
      "Number of rows with inconsistent home planets by last name: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "planet_consistent_count = 0\n",
    "planet_inconsistent_count = 0\n",
    "\n",
    "# Iterate through each last name group\n",
    "for last_name, group_df in df.groupby('LastName'):\n",
    "    if len(group_df) > 1:  # Exclude last names with only one passenger\n",
    "        # Get unique non-NaN HomePlanet values\n",
    "        unique_home_planets = group_df['HomePlanet'].dropna().unique()\n",
    "        \n",
    "        if len(unique_home_planets) <= 1:\n",
    "            # All rows in this group are consistent in HomePlanet\n",
    "            planet_consistent_count += len(group_df)\n",
    "        else:\n",
    "            # Some rows in this group are inconsistent in HomePlanet\n",
    "            planet_inconsistent_count += len(group_df)\n",
    "\n",
    "print(f\"Number of rows with consistent home planets by last name: {planet_consistent_count}\")\n",
    "print(f\"Number of rows with inconsistent home planets by last name: {planet_inconsistent_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of children under the age of 13 having no bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bills'] = df['RoomService'] + df['FoodCourt'] + df['ShoppingMall'] + df['Spa'] + df['VRDeck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for passengers under the age of 13 (excluding NaN Bills):\n",
      "   Total Under 13  Bills = 0  Bills != 0  Consistency Ratio\n",
      "0            1030       1030           0                1.0\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows with NaN values in Bills\n",
    "df_filtered = df[df['Bills'].notna()]\n",
    "\n",
    "# Check if passengers under the age of 13 have bills = 0\n",
    "under_13 = df_filtered[df_filtered['Age'] < 13]\n",
    "under_13_bills_zero = under_13['Bills'] == 0\n",
    "\n",
    "# Calculate summary statistics\n",
    "total_under_13 = len(under_13)\n",
    "bills_zero_under_13 = under_13_bills_zero.sum()\n",
    "bills_not_zero_under_13 = total_under_13 - bills_zero_under_13\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Total Under 13': [total_under_13],\n",
    "    'Bills = 0': [bills_zero_under_13],\n",
    "    'Bills != 0': [bills_not_zero_under_13],\n",
    "    'Consistency Ratio': [bills_zero_under_13 / total_under_13]\n",
    "})\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Summary statistics for passengers under the age of 13 (excluding NaN Bills):\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of those in CryoSleep having no bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for passengers under the age of 13 (excluding NaN Bills):\n",
      "   Total CryoSleep  Bills == 0  Bills != 0  Consistency Ratio\n",
      "0             4068        4068           0                1.0\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows with NaN values in Bills\n",
    "df_filtered = df[df['Bills'].notna()]\n",
    "\n",
    "# Check if passengers under the age of 13 have bills = 0\n",
    "cryo = df_filtered[df_filtered['CryoSleep'] == True]\n",
    "cryo_bills_zero = cryo['Bills'] == 0\n",
    "\n",
    "# Calculate summary statistics\n",
    "total_in_cryo = len(cryo)\n",
    "cryo_bills_zero = cryo_bills_zero.sum()\n",
    "cryo_bills_not_zero = total_in_cryo - cryo_bills_zero\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Total CryoSleep': [total_in_cryo],\n",
    "    'Bills == 0': [cryo_bills_zero],\n",
    "    'Bills != 0': [cryo_bills_not_zero],\n",
    "    'Consistency Ratio': [cryo_bills_zero / total_in_cryo]\n",
    "})\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Summary statistics for passengers under the age of 13 (excluding NaN Bills):\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabins shared by more than one group (with more than one member):\n",
      "Series([], Name: Group, dtype: object)\n",
      "\n",
      "Total multi-member cabins: 1684\n",
      "Multi-member cabins shared by multiple groups: 0\n",
      "Multi-member cabins unique to one group: 1684\n"
     ]
    }
   ],
   "source": [
    "# Filter cabins with more than one member\n",
    "cabin_counts = df['Cabin'].value_counts()\n",
    "multi_member_cabins = cabin_counts[cabin_counts > 1].index\n",
    "\n",
    "# Group by Cabin and list unique groups for each Cabin with more than one member\n",
    "cabin_group_mapping = df[df['Cabin'].isin(multi_member_cabins)].groupby('Cabin')['Group'].unique()\n",
    "\n",
    "# Check if any Cabin is associated with more than one group\n",
    "shared_cabins = cabin_group_mapping[cabin_group_mapping.apply(lambda groups: len(groups) > 1)]\n",
    "\n",
    "# Print the results\n",
    "print(\"Cabins shared by more than one group (with more than one member):\")\n",
    "print(shared_cabins)\n",
    "\n",
    "# Summary statistics\n",
    "total_multi_member_cabins = len(cabin_group_mapping)\n",
    "shared_cabin_count = len(shared_cabins)\n",
    "unique_cabin_count = total_multi_member_cabins - shared_cabin_count\n",
    "\n",
    "print(f\"\\nTotal multi-member cabins: {total_multi_member_cabins}\")\n",
    "print(f\"Multi-member cabins shared by multiple groups: {shared_cabin_count}\")\n",
    "print(f\"Multi-member cabins unique to one group: {unique_cabin_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence of home planets restricting which deck a passenger's cabin is on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet  Earth  Europa  Mars\n",
      "CabinDeck                      \n",
      "A               0     346     0\n",
      "B               0    1124     0\n",
      "C               0    1081     0\n",
      "D               0     296   406\n",
      "E             583     197   508\n",
      "F            2426       0  1713\n",
      "G            3700       0     0\n",
      "T               0      10     0\n"
     ]
    }
   ],
   "source": [
    "# Group by 'HomePlanet' and 'CabinDeck' and count occurrences\n",
    "deck_counts = df.groupby(['HomePlanet', 'CabinDeck']).size().reset_index(name='Count')\n",
    "\n",
    "# Pivot the table to get a better overview\n",
    "pivot_table = deck_counts.pivot(index='CabinDeck', columns='HomePlanet', values='Count').fillna(0).astype(int)\n",
    "\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CabinDecks for passengers with bills = 0 in groups with multiple CabinDecks:\n",
      "HomePlanet: Earth\n",
      "  CabinDeck: G, Count: 526\n",
      "HomePlanet: Mars\n",
      "  CabinDeck: F, Count: 160\n",
      "  CabinDeck: E, Count: 47\n",
      "HomePlanet: Europa\n",
      "  CabinDeck: B, Count: 11\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Iterate through each group\n",
    "for group, group_df in df.groupby('Group'):\n",
    "    # Check if within the group there are more than one CabinDeck\n",
    "    unique_decks = group_df['CabinDeck'].dropna().unique()\n",
    "    \n",
    "    if len(unique_decks) > 1:\n",
    "        # Find passengers with bills = 0\n",
    "        zero_bill_passengers = group_df[(group_df['Bills'] == 0)  & (group_df['HomePlanet'].notna())]\n",
    "        \n",
    "        for idx, passenger in zero_bill_passengers.iterrows():\n",
    "            home_planet = passenger['HomePlanet']\n",
    "            cabin_deck = passenger['CabinDeck']\n",
    "            \n",
    "            if home_planet not in results:\n",
    "                results[home_planet] = []\n",
    "            \n",
    "            results[home_planet].append(cabin_deck)\n",
    "\n",
    "# Print the results\n",
    "print(\"CabinDecks for passengers with bills = 0 in groups with multiple CabinDecks:\")\n",
    "for home_planet, cabin_decks in results.items():\n",
    "    cabin_deck_counts = pd.Series(cabin_decks).value_counts().to_dict()\n",
    "    print(f\"HomePlanet: {home_planet}\")\n",
    "    for deck, count in cabin_deck_counts.items():\n",
    "        print(f\"  CabinDeck: {deck}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_comp = pd.read_csv('data/31remaining.csv')\n",
    "df_to_comp = df_to_comp.rename(columns = {'Number':'CabinNumber'})\n",
    "df_to_comp['CabinNumber'] = df_to_comp['CabinNumber'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9267 G/1077/S F/1267/S\n",
      "12651 A/94/P nan\n",
      "12668 B/297/P nan\n"
     ]
    }
   ],
   "source": [
    "for index,row in df.iterrows():\n",
    "    if not (pd.isna(row.Cabin) and pd.isna(df_to_comp.iloc[index].Cabin)):\n",
    "        if row.Cabin != df_to_comp.iloc[index].Cabin:\n",
    "            print(index,row.Cabin, df_to_comp.iloc[index].Cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512\n",
      "1513\n",
      "2778\n",
      "7216\n"
     ]
    }
   ],
   "source": [
    "for index,row in df_to_comp.iterrows():\n",
    "    if row.HomePlanet == 'Earth':\n",
    "        if row.Deck == 'E':\n",
    "            if row.GroupSize == 2:\n",
    "                if row.Bills == 0:\n",
    "                    if df_to_comp[df_to_comp.Group == row.Group].Deck.nunique() == 1:\n",
    "                        print(index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spaceenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
