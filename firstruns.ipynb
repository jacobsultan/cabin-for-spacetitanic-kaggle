{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('pre_processed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_deck_and_side_from_cabin(df):\n",
    "    # Define a mask to identify rows where 'Number' is NaN and 'Cabin' is not NaN\n",
    "    mask = df['Number'].isna() & df['Cabin'].notna()\n",
    "    \n",
    "    # Use the mask to update only the filtered rows, converting types appropriately\n",
    "    df.loc[mask, ['Deck', 'Number', 'Side']] = df.loc[mask, 'Cabin'].apply(\n",
    "        lambda x: pd.Series({\n",
    "            'Deck': x.split('/')[0],\n",
    "            'Number': int(x.split('/')[1]),  # Explicit conversion to integer here\n",
    "            'Side': x.split('/')[2]\n",
    "        })\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decks_by_planet = {\n",
    "    'Earth':['E','F','G'],\n",
    "    'Europa': ['A','B','C','D','E','T'],\n",
    "    'Mars': ['D','E','F']\n",
    "}\n",
    "\n",
    "decks_by_planet_no_bills = {\n",
    "    'Earth':['G'],\n",
    "    'Europa':['B'],\n",
    "    'Mars': ['E','F']\n",
    "}\n",
    "\n",
    "planet_by_deck = {\n",
    "    'A':['Europa'],'B':['Europa'],'C':['Europa'],'D':['Europa','Mars'],'E':['Europa','Mars','Earth'],\n",
    "    'F':['Earth','Mars'],'G':['Earth'],'T':['Europa']\n",
    "}\n",
    "\n",
    "homeplanets = ['Earth', 'Europa', 'Mars']\n",
    "\n",
    "all_cabin_sides = ['P','S']\n",
    "\n",
    "all_cabin_decks = list(df.dropna(subset = ['Deck']).Deck.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_decks_in_group(df,row):\n",
    "    return len(df[df.Group == row.Group].dropna(subset ='Deck').Deck.unique()) > 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_potential_decks(df):\n",
    "    def func_potential_decks(row):\n",
    "        if pd.isna(row.Cabin):\n",
    "            if row.Bills == 0 and not pd.isna(row.HomePlanet):\n",
    "                if len(df[df.Group == row.Group].dropna(subset = 'Deck').Deck.unique()) > 1:\n",
    "                    return decks_by_planet_no_bills[row.HomePlanet]\n",
    "            if not pd.isna(row.HomePlanet):\n",
    "                return decks_by_planet[row.HomePlanet]\n",
    "            else:\n",
    "                return all_cabin_decks\n",
    "    df['potential_decks'] = df.apply(func_potential_decks, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_potential_decks(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling missed Cabins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_of_utilised_cabins(df):\n",
    "    used_cabins = {}\n",
    "    for deck in all_cabin_decks:\n",
    "        cab = {}\n",
    "        for side in all_cabin_sides:\n",
    "            rooms = list(df[(df.Deck == deck) & (df.Side == side)].dropna(subset = 'Number').Number.unique())\n",
    "            rooms.sort()\n",
    "            cab[side] = rooms\n",
    "        used_cabins[deck] = cab\n",
    "    return used_cabins\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fill people that must be sharing a room with people in the same group\n",
    "ie, from their chome planet we know the decks they could be in, if the side and number below and above are one above and one below then they must be sharing with someone from their group. make sure that their group has only one cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to make sure is only one person  with cabin being na in the group otherwise one na might be in another cabin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for row in dataframe\n",
    "\n",
    "if cabin.isna() and homeplanet is known,\n",
    " for potential decks in homeplanets remit ie europa check a, b , c in dataframe up to that point and over that point, see if any have a free space and if not then fill it with the one in the same group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checks(df):\n",
    "    for home in homeplanets:\n",
    "        print(\"\\n\" + home)\n",
    "        print(df[df.HomePlanet == home].Deck.value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('before_impute.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df3 = df.copy()\n",
    "df4 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding groups that have more than 1 member that all share the same cabin and that dont have other nans in group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId            0\n",
       "HomePlanet            13\n",
       "CryoSleep            310\n",
       "Cabin                299\n",
       "Destination          274\n",
       "Age                  270\n",
       "VIP                  296\n",
       "RoomService          263\n",
       "FoodCourt            289\n",
       "ShoppingMall         306\n",
       "Spa                  284\n",
       "VRDeck               268\n",
       "Name                 294\n",
       "Set                    0\n",
       "Transported         4277\n",
       "Group                  0\n",
       "GroupNumber            0\n",
       "Deck                 299\n",
       "Number               299\n",
       "Side                 299\n",
       "FirstName            294\n",
       "LastName             294\n",
       "GroupSize              0\n",
       "Bills                785\n",
       "potential_decks    12671\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one room available and its alone in its group ( should be first in cabin fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rooms_to_fill(df):\n",
    "    rooms = {}\n",
    "    for deck in all_cabin_decks:\n",
    "        for side in all_cabin_sides:\n",
    "            rooms_seen = list(df[(df.Deck == deck) & (df.Side == side)].dropna(subset = ['Number']).Number.unique())\n",
    "            largest_room_number = int(max(list(df[(df.Deck == deck) & (df.Side == side)].dropna(subset = ['Number']).Number.unique())))\n",
    "            for i in range(largest_room_number):\n",
    "                if i not in rooms_seen:\n",
    "                    if deck not in rooms:\n",
    "                        rooms[deck] = {'P':[],'S':[]}\n",
    "                    rooms[deck][side].append(i)\n",
    "    return rooms\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def empty_room_one_compatible(df):\n",
    "    count = 0\n",
    "    empty_cabins = rooms_to_fill(df) \n",
    "    for deck in empty_cabins.keys():\n",
    "        for side in empty_cabins[deck].keys():\n",
    "            for number in empty_cabins[deck][side]:\n",
    "                print(\"count\",count)\n",
    "                count +=1\n",
    "                indices_of_compatible_rows = []\n",
    "                temp = df[(df.Cabin.isna())]\n",
    "                for index,row in temp.iterrows():\n",
    "                    if deck not in row.potential_decks:\n",
    "                        continue\n",
    "                            \n",
    "                    before_slice = df.iloc[:index]\n",
    "                    after_slice = df.iloc[index+1:] \n",
    "                    before = list(before_slice[(before_slice.Deck == deck) & (before_slice.Side == side)].Number.unique())\n",
    "                    if len(before) > 0:\n",
    "                        if max(before) < number:\n",
    "                            if min(list(after_slice[(after_slice.Deck == deck) & (after_slice.Side == side)].Number.unique())) > number:\n",
    "                                indices_of_compatible_rows.append(index)\n",
    "                if len(indices_of_compatible_rows) == 1:\n",
    "                    df.loc[indices_of_compatible_rows[0], 'Cabin'] = deck + \"/\" + str(int(number)) + \"/\" + side\n",
    "\n",
    "    df = fill_deck_and_side_from_cabin(df)\n",
    "    return df\n",
    "                    \n",
    "                    \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 0\n",
      "count 1\n",
      "count 2\n",
      "count 3\n",
      "count 4\n",
      "count 5\n",
      "count 6\n",
      "count 7\n",
      "count 8\n",
      "count 9\n",
      "count 10\n",
      "count 11\n",
      "count 12\n",
      "count 13\n",
      "count 14\n",
      "count 15\n",
      "count 16\n",
      "count 17\n",
      "count 18\n",
      "count 19\n",
      "count 20\n",
      "count 21\n",
      "count 22\n",
      "count 23\n",
      "count 24\n",
      "count 25\n",
      "count 26\n",
      "count 27\n",
      "count 28\n",
      "count 29\n",
      "count 30\n",
      "count 31\n",
      "count 32\n",
      "count 33\n",
      "count 34\n",
      "count 35\n",
      "count 36\n",
      "count 37\n",
      "count 38\n",
      "count 39\n",
      "count 40\n",
      "count 41\n",
      "count 42\n",
      "count 43\n",
      "count 44\n",
      "count 45\n",
      "count 46\n",
      "count 47\n",
      "count 48\n",
      "count 49\n",
      "count 50\n",
      "count 51\n",
      "count 52\n",
      "count 53\n",
      "count 54\n"
     ]
    }
   ],
   "source": [
    "df4 = empty_room_one_compatible(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId            0\n",
       "HomePlanet            13\n",
       "CryoSleep            310\n",
       "Cabin                161\n",
       "Destination          274\n",
       "Age                  270\n",
       "VIP                  296\n",
       "RoomService          263\n",
       "FoodCourt            289\n",
       "ShoppingMall         306\n",
       "Spa                  284\n",
       "VRDeck               268\n",
       "Name                 294\n",
       "Set                    0\n",
       "Transported         4277\n",
       "Group                  0\n",
       "GroupNumber            0\n",
       "Deck                 161\n",
       "Number               161\n",
       "Side                 161\n",
       "FirstName            294\n",
       "LastName             294\n",
       "GroupSize              0\n",
       "Bills                785\n",
       "potential_decks    12671\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# there arent any free rooms for it so has to share\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2442\n",
      "2970\n",
      "4569\n",
      "4751\n",
      "12174\n"
     ]
    }
   ],
   "source": [
    "def no_free_rooms_so_shares(df):\n",
    "    for index, passenger in df[df.Cabin.isna()].iterrows():\n",
    "        options = False\n",
    "        for deck in passenger.potential_decks:\n",
    "            for side in cabin_sides:\n",
    "                \n",
    "                before_slice = df.iloc[:index]\n",
    "                after_slice = df.iloc[index+1:] \n",
    "                top_room_number_before = np.max(before_slice[(before_slice.Deck == deck) & (before_slice.Side == side)].Number)\n",
    "                smallest_room_number_after = np.min(after_slice[(after_slice.Deck == deck) & (after_slice.Side == side)].Number)\n",
    "                \n",
    "                if top_room_number_before + 1 != smallest_room_number_after:\n",
    "                    if pd.isna(top_room_number_before) and smallest_room_number_after == 0:\n",
    "                        continue\n",
    "                    elif top_room_number_before == smallest_room_number_after:\n",
    "                        continue\n",
    "                    else:\n",
    "                        options = True\n",
    "                        break\n",
    "            if options:\n",
    "                break\n",
    "        if not options:\n",
    "            other_group_member = df[(df.Group == passenger.Group) & (~df.Cabin.isna()) & (df.Deck.isin(passenger.potential_decks))]\n",
    "            print(index)\n",
    "            if len(other_group_member.Cabin.unique()) == 1:\n",
    "                \n",
    "                df.loc[index,'Cabin'] = other_group_member.iloc[0].Cabin\n",
    "                \n",
    "    df[['Deck','Number','Side']] = df.apply(fill_deck_cabin_side,axis = 1)\n",
    "    return df\n",
    "  \n",
    "            # Slice the DataFrame first and then apply the boolean mask\n",
    "\n",
    "df2 = no_free_rooms_so_shares(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual imputes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[4233,'Cabin'] = 'B/98/P'\n",
    "df2.loc[4254,'Cabin'] = 'B/99/P'\n",
    "df2.loc[6493,'Cabin'] = 'E/300/S'\n",
    "df2.loc[6514,'Cabin'] = 'E/301/S'\n",
    "df2.loc[12892,'Cabin'] = 'F/1785/S'\n",
    "df2.loc[12893,'Cabin'] = 'F/1785/S'\n",
    "df2.loc[9265,'Cabin'] = 'F/1267/S'\n",
    "df2.loc[9267,'Cabin'] = 'F/1267/S'\n",
    "df2[['Deck','Number','Side']] = df2.apply(fill_deck_cabin_side,axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId            0\n",
       "HomePlanet            13\n",
       "CryoSleep            310\n",
       "Cabin                 68\n",
       "Destination          274\n",
       "Age                  270\n",
       "VIP                  296\n",
       "RoomService          263\n",
       "FoodCourt            289\n",
       "ShoppingMall         306\n",
       "Spa                  284\n",
       "VRDeck               268\n",
       "Name                 294\n",
       "Set                    0\n",
       "Transported         4277\n",
       "Group                  0\n",
       "GroupNumber            0\n",
       "Deck                  68\n",
       "Number                68\n",
       "Side                  68\n",
       "FirstName            294\n",
       "LastName             294\n",
       "GroupSize              0\n",
       "Bills                785\n",
       "potential_decks    12671\n",
       "dtype: int64"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cases\n",
    "* there arent any free rooms for it so has to share\n",
    "* its the only person that could fill that room "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# free room where only one person can take it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rooms_to_fill(df):\n",
    "    rooms = {}\n",
    "    for deck in all_cabin_decks:\n",
    "        for side in all_cabin_sides:\n",
    "            rooms_seen = list(df[(df.Deck == deck) & (df.Side == side)].dropna(subset = ['Number']).Number.unique())\n",
    "            largest_room_number = int(max(list(df[(df.Deck == deck) & (df.Side == side)].dropna(subset = ['Number']).Number.unique())))\n",
    "            for i in range(largest_room_number):\n",
    "                if i not in rooms_seen:\n",
    "                    if deck not in rooms:\n",
    "                        rooms[deck] = {'P':[],'S':[]}\n",
    "                    rooms[deck][side].append(i)\n",
    "    return rooms\n",
    "\n",
    "rooms = rooms_to_fill(df2)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def sum_lengths(d):\n",
    "    total_length = 0\n",
    "    for outer_key in d:\n",
    "        for inner_key in d[outer_key]:\n",
    "            array = d[outer_key][inner_key]\n",
    "            total_length += len(array)\n",
    "    return total_length\n",
    "\n",
    "sum_lengths(rooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_by_empty_room(df):\n",
    "    for deck in rooms.keys():\n",
    "        for side in ['P','S']:\n",
    "            for number in rooms[deck][side]:\n",
    "                indices_matching = []\n",
    "                temp = df[(df.Cabin.isna())]\n",
    "                for index,row in temp.iterrows():\n",
    "                    if deck not in row.potential_decks:\n",
    "                        continue\n",
    "                            \n",
    "                    before_slice = df.iloc[:index]\n",
    "                    after_slice = df.iloc[index+1:] \n",
    "                    if len(list(before_slice[(before_slice.Deck == deck) & (before_slice.Side == side)].Number.unique())) > 0:\n",
    "                        if max(list(before_slice[(before_slice.Deck == deck) & (before_slice.Side == side)].Number.unique())) < number:\n",
    "                            if min(list(after_slice[(after_slice.Deck == deck) & (after_slice.Side == side)].Number.unique())) > number:\n",
    "                                indices_matching.append(index)\n",
    "                if len(indices_matching) == 1:\n",
    "                    df.loc[indices_matching[0],'Cabin'] = deck + \"/\" + str(number) + \"/\" + side\n",
    "                    df.loc[indices_matching[0],['Side','Deck','Number']] = [side,deck,number]\n",
    "fill_by_empty_room(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId            0\n",
       "HomePlanet            13\n",
       "CryoSleep            310\n",
       "Cabin                161\n",
       "Destination          274\n",
       "Age                  270\n",
       "VIP                  296\n",
       "RoomService          263\n",
       "FoodCourt            289\n",
       "ShoppingMall         306\n",
       "Spa                  284\n",
       "VRDeck               268\n",
       "Name                 294\n",
       "Set                    0\n",
       "Transported         4277\n",
       "Group                  0\n",
       "GroupNumber            0\n",
       "Deck                 161\n",
       "Number               161\n",
       "Side                 161\n",
       "FirstName            294\n",
       "LastName             294\n",
       "GroupSize              0\n",
       "Bills                785\n",
       "potential_decks    12671\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>...</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Number</th>\n",
       "      <th>Side</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>GroupSize</th>\n",
       "      <th>Bills</th>\n",
       "      <th>potential_decks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>7125_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>41.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7125</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nakes</td>\n",
       "      <td>Eccle</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[D, E, F]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep Cabin    Destination   Age    VIP  \\\n",
       "9999     7125_01       Mars      True   NaN  PSO J318.5-22  41.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall  ...  Group  GroupNumber Deck  \\\n",
       "9999          0.0        0.0           0.0  ...   7125            1  NaN   \n",
       "\n",
       "     Number Side  FirstName  LastName GroupSize  Bills potential_decks  \n",
       "9999    NaN  NaN      Nakes     Eccle         1    0.0       [D, E, F]  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.Group == 7125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('cabin_to_compare.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId            0\n",
       "HomePlanet            13\n",
       "CryoSleep            310\n",
       "Cabin                299\n",
       "Destination          274\n",
       "Age                  270\n",
       "VIP                  296\n",
       "RoomService          263\n",
       "FoodCourt            289\n",
       "ShoppingMall         306\n",
       "Spa                  284\n",
       "VRDeck               268\n",
       "Name                 294\n",
       "Set                    0\n",
       "Transported         4277\n",
       "Group                  0\n",
       "GroupNumber            0\n",
       "Deck                 299\n",
       "Number               299\n",
       "Side                 299\n",
       "FirstName            294\n",
       "LastName             294\n",
       "GroupSize              0\n",
       "Bills                785\n",
       "potential_decks    12671\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remaining cabins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# which cabin for empty people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remaining_cabins(df):\n",
    "    for index, passenger in df[df.Cabin.isna()].iterrows():\n",
    "        print(\"\\nindex\", index)\n",
    "        print(\"passenger\",passenger.PassengerId)\n",
    "        print(\"GroupSize\", passenger.GroupSize)\n",
    "        options = []\n",
    "        for deck in decks_by_planet[passenger.HomePlanet]:\n",
    "            for side in cabin_sides:\n",
    "                \n",
    "                before_slice = df.iloc[:index]\n",
    "                after_slice = df.iloc[index+1:] \n",
    "                top_room_number_before = np.max(before_slice[(before_slice.Deck == deck) & (before_slice.Side == side)].Number)\n",
    "                smallest_room_number_after = np.min(after_slice[(after_slice.Deck == deck) & (after_slice.Side == side)].Number)\n",
    "                \n",
    "                if top_room_number_before + 1 != smallest_room_number_after:\n",
    "                    if pd.isna(top_room_number_before) and smallest_room_number_after == 0:\n",
    "                        continue\n",
    "                    elif top_room_number_before == smallest_room_number_after:\n",
    "                        continue\n",
    "                    else:\n",
    "                        options.append([deck,side,top_room_number_before,smallest_room_number_after])\n",
    "        print(options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# which people for empty cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_by_empty_room(df):\n",
    "    for deck in rooms.keys():\n",
    "        for side in ['P','S']:\n",
    "            for number in rooms[deck][side]:\n",
    "                indices_matching = []\n",
    "                print()\n",
    "                print('deck',deck,'side',side,'number',number)\n",
    "                temp = df[(df.Cabin.isna()) & (pd.isna(df.HomePlanet) | df.HomePlanet.isin(planet_by_deck[deck]))]\n",
    "                for index,row in temp.iterrows():\n",
    "                    before_slice = df.iloc[:index]\n",
    "                    after_slice = df.iloc[index+1:] \n",
    "                    if max(list(before_slice[(before_slice.Deck == deck) & (before_slice.Side == side)].Number.unique())) < number:\n",
    "                        if min(list(after_slice[(after_slice.Deck == deck) & (after_slice.Side == side)].Number.unique())) > number:\n",
    "                            indices_matching.append(index)\n",
    "                print(df.iloc[indices_matching].PassengerId)\n",
    "                print()\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what can be deduced with these cabins now filled ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                   0293_01\n",
       "HomePlanet                     Europa\n",
       "CryoSleep                        True\n",
       "Cabin                             NaN\n",
       "Destination               TRAPPIST-1e\n",
       "Age                              47.0\n",
       "VIP                             False\n",
       "RoomService                       0.0\n",
       "FoodCourt                         0.0\n",
       "ShoppingMall                      0.0\n",
       "Spa                               0.0\n",
       "VRDeck                            0.0\n",
       "Name                 Tauxon Suptibler\n",
       "Set                              Test\n",
       "Transported                       NaN\n",
       "Group                             293\n",
       "GroupNumber                         1\n",
       "Deck                              NaN\n",
       "Number                            NaN\n",
       "Side                              NaN\n",
       "FirstName                      Tauxon\n",
       "LastName                    Suptibler\n",
       "GroupSize                           1\n",
       "Bills                             0.0\n",
       "potential_decks    [A, B, C, D, E, T]\n",
       "Name: 404, dtype: object"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[404]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CryoSleep\n",
       "False    119\n",
       "True      73\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Deck == 'C') & (df.GroupSize == 1) & (df.Side == 'S')].CryoSleep.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "used = utilised_cabins(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P': [0.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  3.0,\n",
       "  4.0,\n",
       "  5.0,\n",
       "  6.0,\n",
       "  7.0,\n",
       "  8.0,\n",
       "  9.0,\n",
       "  10.0,\n",
       "  11.0,\n",
       "  12.0,\n",
       "  14.0,\n",
       "  15.0,\n",
       "  16.0,\n",
       "  17.0,\n",
       "  18.0,\n",
       "  19.0,\n",
       "  20.0,\n",
       "  21.0,\n",
       "  22.0,\n",
       "  23.0,\n",
       "  24.0,\n",
       "  25.0,\n",
       "  26.0,\n",
       "  27.0,\n",
       "  28.0,\n",
       "  29.0,\n",
       "  30.0,\n",
       "  31.0,\n",
       "  32.0,\n",
       "  33.0,\n",
       "  34.0,\n",
       "  35.0,\n",
       "  36.0,\n",
       "  37.0,\n",
       "  38.0,\n",
       "  39.0,\n",
       "  40.0,\n",
       "  41.0,\n",
       "  42.0,\n",
       "  43.0,\n",
       "  44.0,\n",
       "  45.0,\n",
       "  46.0,\n",
       "  47.0,\n",
       "  48.0,\n",
       "  49.0,\n",
       "  50.0,\n",
       "  51.0,\n",
       "  52.0,\n",
       "  53.0,\n",
       "  54.0,\n",
       "  55.0,\n",
       "  56.0,\n",
       "  57.0,\n",
       "  58.0,\n",
       "  59.0,\n",
       "  60.0,\n",
       "  61.0,\n",
       "  62.0,\n",
       "  63.0,\n",
       "  64.0,\n",
       "  65.0,\n",
       "  66.0,\n",
       "  67.0,\n",
       "  68.0,\n",
       "  69.0,\n",
       "  70.0,\n",
       "  71.0,\n",
       "  72.0,\n",
       "  73.0,\n",
       "  74.0,\n",
       "  75.0,\n",
       "  76.0,\n",
       "  77.0,\n",
       "  78.0,\n",
       "  79.0,\n",
       "  80.0,\n",
       "  81.0,\n",
       "  82.0,\n",
       "  83.0,\n",
       "  84.0,\n",
       "  85.0,\n",
       "  86.0,\n",
       "  87.0,\n",
       "  88.0,\n",
       "  89.0,\n",
       "  90.0,\n",
       "  91.0,\n",
       "  92.0,\n",
       "  93.0,\n",
       "  94.0,\n",
       "  95.0,\n",
       "  96.0,\n",
       "  97.0,\n",
       "  98.0,\n",
       "  99.0,\n",
       "  100.0,\n",
       "  101.0,\n",
       "  102.0,\n",
       "  103.0,\n",
       "  104.0,\n",
       "  105.0,\n",
       "  106.0,\n",
       "  107.0,\n",
       "  108.0,\n",
       "  109.0,\n",
       "  110.0,\n",
       "  111.0,\n",
       "  112.0,\n",
       "  113.0,\n",
       "  114.0,\n",
       "  115.0,\n",
       "  116.0,\n",
       "  117.0,\n",
       "  118.0,\n",
       "  119.0,\n",
       "  120.0,\n",
       "  121.0,\n",
       "  122.0,\n",
       "  123.0,\n",
       "  124.0,\n",
       "  125.0,\n",
       "  126.0,\n",
       "  127.0,\n",
       "  128.0,\n",
       "  129.0,\n",
       "  130.0,\n",
       "  131.0,\n",
       "  132.0,\n",
       "  133.0,\n",
       "  134.0,\n",
       "  135.0,\n",
       "  136.0,\n",
       "  137.0,\n",
       "  138.0,\n",
       "  139.0,\n",
       "  140.0,\n",
       "  141.0,\n",
       "  142.0,\n",
       "  143.0,\n",
       "  144.0,\n",
       "  145.0,\n",
       "  146.0,\n",
       "  147.0,\n",
       "  148.0,\n",
       "  149.0,\n",
       "  150.0,\n",
       "  151.0,\n",
       "  152.0,\n",
       "  153.0,\n",
       "  154.0,\n",
       "  155.0,\n",
       "  156.0,\n",
       "  157.0,\n",
       "  158.0,\n",
       "  159.0,\n",
       "  160.0,\n",
       "  161.0,\n",
       "  162.0,\n",
       "  163.0,\n",
       "  164.0,\n",
       "  165.0,\n",
       "  166.0,\n",
       "  167.0,\n",
       "  168.0,\n",
       "  169.0,\n",
       "  170.0,\n",
       "  171.0,\n",
       "  172.0,\n",
       "  173.0,\n",
       "  174.0,\n",
       "  175.0,\n",
       "  176.0,\n",
       "  177.0,\n",
       "  178.0,\n",
       "  179.0,\n",
       "  180.0,\n",
       "  181.0,\n",
       "  182.0,\n",
       "  183.0,\n",
       "  184.0,\n",
       "  185.0,\n",
       "  186.0,\n",
       "  187.0,\n",
       "  188.0,\n",
       "  189.0,\n",
       "  190.0,\n",
       "  191.0,\n",
       "  192.0,\n",
       "  193.0,\n",
       "  194.0,\n",
       "  195.0,\n",
       "  196.0,\n",
       "  197.0,\n",
       "  198.0,\n",
       "  199.0,\n",
       "  200.0,\n",
       "  201.0,\n",
       "  202.0,\n",
       "  203.0,\n",
       "  204.0,\n",
       "  205.0,\n",
       "  206.0,\n",
       "  207.0,\n",
       "  208.0,\n",
       "  209.0,\n",
       "  210.0,\n",
       "  211.0,\n",
       "  212.0,\n",
       "  213.0,\n",
       "  214.0,\n",
       "  215.0,\n",
       "  216.0,\n",
       "  217.0,\n",
       "  218.0,\n",
       "  219.0,\n",
       "  220.0,\n",
       "  221.0,\n",
       "  222.0,\n",
       "  223.0,\n",
       "  224.0,\n",
       "  225.0,\n",
       "  226.0,\n",
       "  227.0,\n",
       "  228.0,\n",
       "  229.0,\n",
       "  230.0,\n",
       "  231.0,\n",
       "  232.0,\n",
       "  233.0,\n",
       "  234.0,\n",
       "  235.0,\n",
       "  236.0,\n",
       "  237.0,\n",
       "  238.0,\n",
       "  239.0,\n",
       "  240.0,\n",
       "  241.0,\n",
       "  242.0,\n",
       "  243.0,\n",
       "  244.0,\n",
       "  245.0,\n",
       "  246.0,\n",
       "  247.0,\n",
       "  248.0,\n",
       "  249.0,\n",
       "  250.0,\n",
       "  251.0,\n",
       "  252.0,\n",
       "  253.0,\n",
       "  254.0,\n",
       "  255.0,\n",
       "  256.0,\n",
       "  257.0,\n",
       "  258.0,\n",
       "  259.0,\n",
       "  260.0,\n",
       "  261.0,\n",
       "  262.0,\n",
       "  263.0,\n",
       "  264.0,\n",
       "  265.0,\n",
       "  266.0,\n",
       "  267.0,\n",
       "  268.0,\n",
       "  269.0,\n",
       "  270.0,\n",
       "  271.0,\n",
       "  272.0,\n",
       "  273.0,\n",
       "  274.0,\n",
       "  275.0,\n",
       "  276.0,\n",
       "  277.0,\n",
       "  278.0,\n",
       "  279.0,\n",
       "  280.0,\n",
       "  281.0,\n",
       "  282.0,\n",
       "  283.0,\n",
       "  284.0,\n",
       "  285.0,\n",
       "  286.0,\n",
       "  287.0,\n",
       "  288.0,\n",
       "  289.0,\n",
       "  290.0,\n",
       "  291.0,\n",
       "  292.0,\n",
       "  293.0,\n",
       "  294.0,\n",
       "  295.0,\n",
       "  296.0,\n",
       "  297.0,\n",
       "  298.0,\n",
       "  299.0,\n",
       "  300.0,\n",
       "  301.0],\n",
       " 'S': [0.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  3.0,\n",
       "  4.0,\n",
       "  5.0,\n",
       "  6.0,\n",
       "  7.0,\n",
       "  8.0,\n",
       "  9.0,\n",
       "  10.0,\n",
       "  11.0,\n",
       "  12.0,\n",
       "  13.0,\n",
       "  14.0,\n",
       "  15.0,\n",
       "  16.0,\n",
       "  17.0,\n",
       "  18.0,\n",
       "  19.0,\n",
       "  20.0,\n",
       "  21.0,\n",
       "  22.0,\n",
       "  23.0,\n",
       "  24.0,\n",
       "  25.0,\n",
       "  26.0,\n",
       "  27.0,\n",
       "  28.0,\n",
       "  29.0,\n",
       "  30.0,\n",
       "  31.0,\n",
       "  32.0,\n",
       "  33.0,\n",
       "  34.0,\n",
       "  35.0,\n",
       "  36.0,\n",
       "  37.0,\n",
       "  38.0,\n",
       "  39.0,\n",
       "  40.0,\n",
       "  41.0,\n",
       "  42.0,\n",
       "  43.0,\n",
       "  44.0,\n",
       "  45.0,\n",
       "  46.0,\n",
       "  47.0,\n",
       "  48.0,\n",
       "  49.0,\n",
       "  50.0,\n",
       "  51.0,\n",
       "  52.0,\n",
       "  53.0,\n",
       "  54.0,\n",
       "  55.0,\n",
       "  56.0,\n",
       "  57.0,\n",
       "  58.0,\n",
       "  59.0,\n",
       "  60.0,\n",
       "  61.0,\n",
       "  62.0,\n",
       "  63.0,\n",
       "  64.0,\n",
       "  65.0,\n",
       "  66.0,\n",
       "  67.0,\n",
       "  68.0,\n",
       "  69.0,\n",
       "  70.0,\n",
       "  71.0,\n",
       "  72.0,\n",
       "  73.0,\n",
       "  74.0,\n",
       "  75.0,\n",
       "  76.0,\n",
       "  77.0,\n",
       "  78.0,\n",
       "  79.0,\n",
       "  80.0,\n",
       "  81.0,\n",
       "  82.0,\n",
       "  83.0,\n",
       "  84.0,\n",
       "  85.0,\n",
       "  86.0,\n",
       "  87.0,\n",
       "  88.0,\n",
       "  89.0,\n",
       "  90.0,\n",
       "  91.0,\n",
       "  92.0,\n",
       "  93.0,\n",
       "  94.0,\n",
       "  95.0,\n",
       "  96.0,\n",
       "  97.0,\n",
       "  98.0,\n",
       "  99.0,\n",
       "  100.0,\n",
       "  101.0,\n",
       "  102.0,\n",
       "  103.0,\n",
       "  104.0,\n",
       "  105.0,\n",
       "  106.0,\n",
       "  107.0,\n",
       "  108.0,\n",
       "  109.0,\n",
       "  110.0,\n",
       "  111.0,\n",
       "  112.0,\n",
       "  113.0,\n",
       "  114.0,\n",
       "  115.0,\n",
       "  116.0,\n",
       "  117.0,\n",
       "  118.0,\n",
       "  119.0,\n",
       "  120.0,\n",
       "  121.0,\n",
       "  122.0,\n",
       "  123.0,\n",
       "  124.0,\n",
       "  125.0,\n",
       "  126.0,\n",
       "  127.0,\n",
       "  128.0,\n",
       "  129.0,\n",
       "  130.0,\n",
       "  131.0,\n",
       "  132.0,\n",
       "  133.0,\n",
       "  134.0,\n",
       "  135.0,\n",
       "  136.0,\n",
       "  137.0,\n",
       "  138.0,\n",
       "  139.0,\n",
       "  140.0,\n",
       "  141.0,\n",
       "  142.0,\n",
       "  143.0,\n",
       "  144.0,\n",
       "  145.0,\n",
       "  146.0,\n",
       "  147.0,\n",
       "  148.0,\n",
       "  149.0,\n",
       "  150.0,\n",
       "  151.0,\n",
       "  152.0,\n",
       "  153.0,\n",
       "  154.0,\n",
       "  155.0,\n",
       "  156.0,\n",
       "  157.0,\n",
       "  158.0,\n",
       "  159.0,\n",
       "  160.0,\n",
       "  161.0,\n",
       "  162.0,\n",
       "  163.0,\n",
       "  164.0,\n",
       "  165.0,\n",
       "  166.0,\n",
       "  167.0,\n",
       "  168.0,\n",
       "  169.0,\n",
       "  170.0,\n",
       "  171.0,\n",
       "  172.0,\n",
       "  173.0,\n",
       "  174.0,\n",
       "  175.0,\n",
       "  176.0,\n",
       "  177.0,\n",
       "  178.0,\n",
       "  179.0,\n",
       "  180.0,\n",
       "  181.0,\n",
       "  182.0,\n",
       "  183.0,\n",
       "  184.0,\n",
       "  185.0,\n",
       "  186.0,\n",
       "  187.0,\n",
       "  188.0,\n",
       "  189.0,\n",
       "  190.0,\n",
       "  191.0,\n",
       "  192.0,\n",
       "  193.0,\n",
       "  194.0,\n",
       "  195.0,\n",
       "  196.0,\n",
       "  197.0,\n",
       "  198.0,\n",
       "  199.0,\n",
       "  200.0,\n",
       "  201.0,\n",
       "  202.0,\n",
       "  203.0,\n",
       "  204.0,\n",
       "  205.0,\n",
       "  206.0,\n",
       "  207.0,\n",
       "  208.0,\n",
       "  209.0,\n",
       "  210.0,\n",
       "  211.0,\n",
       "  212.0,\n",
       "  213.0,\n",
       "  214.0,\n",
       "  215.0,\n",
       "  216.0,\n",
       "  217.0,\n",
       "  218.0,\n",
       "  219.0,\n",
       "  220.0,\n",
       "  221.0,\n",
       "  222.0,\n",
       "  223.0,\n",
       "  224.0,\n",
       "  225.0,\n",
       "  226.0,\n",
       "  227.0,\n",
       "  228.0,\n",
       "  229.0,\n",
       "  230.0,\n",
       "  231.0,\n",
       "  232.0,\n",
       "  233.0,\n",
       "  234.0,\n",
       "  235.0,\n",
       "  236.0,\n",
       "  237.0,\n",
       "  238.0,\n",
       "  239.0,\n",
       "  240.0,\n",
       "  241.0,\n",
       "  242.0,\n",
       "  243.0,\n",
       "  244.0,\n",
       "  245.0,\n",
       "  246.0,\n",
       "  247.0,\n",
       "  248.0,\n",
       "  249.0,\n",
       "  250.0,\n",
       "  251.0,\n",
       "  252.0,\n",
       "  253.0,\n",
       "  254.0,\n",
       "  255.0,\n",
       "  256.0,\n",
       "  257.0,\n",
       "  258.0,\n",
       "  259.0,\n",
       "  260.0,\n",
       "  261.0,\n",
       "  262.0,\n",
       "  263.0,\n",
       "  264.0,\n",
       "  265.0,\n",
       "  266.0,\n",
       "  267.0,\n",
       "  268.0,\n",
       "  269.0,\n",
       "  270.0,\n",
       "  271.0,\n",
       "  272.0,\n",
       "  273.0,\n",
       "  274.0,\n",
       "  275.0,\n",
       "  276.0,\n",
       "  277.0,\n",
       "  278.0,\n",
       "  279.0,\n",
       "  280.0,\n",
       "  281.0,\n",
       "  282.0,\n",
       "  283.0,\n",
       "  284.0,\n",
       "  285.0,\n",
       "  286.0,\n",
       "  287.0,\n",
       "  288.0,\n",
       "  289.0,\n",
       "  290.0,\n",
       "  291.0,\n",
       "  292.0,\n",
       "  293.0,\n",
       "  294.0,\n",
       "  295.0,\n",
       "  296.0,\n",
       "  297.0,\n",
       "  298.0,\n",
       "  299.0,\n",
       "  300.0,\n",
       "  301.0,\n",
       "  302.0,\n",
       "  303.0,\n",
       "  304.0,\n",
       "  305.0,\n",
       "  306.0,\n",
       "  307.0,\n",
       "  308.0,\n",
       "  309.0,\n",
       "  310.0,\n",
       "  311.0,\n",
       "  312.0,\n",
       "  313.0,\n",
       "  314.0,\n",
       "  315.0,\n",
       "  316.0,\n",
       "  317.0,\n",
       "  318.0,\n",
       "  319.0,\n",
       "  320.0,\n",
       "  321.0,\n",
       "  322.0,\n",
       "  323.0,\n",
       "  324.0,\n",
       "  325.0,\n",
       "  326.0,\n",
       "  327.0,\n",
       "  328.0,\n",
       "  329.0,\n",
       "  330.0,\n",
       "  331.0,\n",
       "  332.0,\n",
       "  333.0,\n",
       "  334.0,\n",
       "  335.0,\n",
       "  336.0,\n",
       "  337.0,\n",
       "  338.0,\n",
       "  339.0,\n",
       "  340.0,\n",
       "  341.0,\n",
       "  342.0,\n",
       "  343.0,\n",
       "  344.0,\n",
       "  345.0,\n",
       "  346.0,\n",
       "  347.0,\n",
       "  348.0,\n",
       "  349.0,\n",
       "  350.0,\n",
       "  351.0,\n",
       "  352.0,\n",
       "  353.0]}"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 12.0,\n",
       " 14.0,\n",
       " 15.0,\n",
       " 16.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 20.0,\n",
       " 21.0,\n",
       " 22.0,\n",
       " 23.0,\n",
       " 24.0,\n",
       " 25.0,\n",
       " 26.0,\n",
       " 27.0,\n",
       " 28.0,\n",
       " 29.0,\n",
       " 30.0,\n",
       " 31.0,\n",
       " 32.0,\n",
       " 33.0,\n",
       " 34.0,\n",
       " 35.0,\n",
       " 36.0,\n",
       " 37.0,\n",
       " 38.0,\n",
       " 39.0,\n",
       " 41.0,\n",
       " 42.0,\n",
       " 43.0,\n",
       " 44.0,\n",
       " 45.0,\n",
       " 46.0,\n",
       " 47.0,\n",
       " 48.0,\n",
       " 49.0,\n",
       " 50.0,\n",
       " 51.0,\n",
       " 52.0,\n",
       " 53.0,\n",
       " 54.0,\n",
       " 55.0,\n",
       " 56.0,\n",
       " 57.0,\n",
       " 58.0,\n",
       " 59.0,\n",
       " 60.0,\n",
       " 61.0,\n",
       " 62.0,\n",
       " 63.0,\n",
       " 64.0,\n",
       " 65.0,\n",
       " 66.0,\n",
       " 67.0,\n",
       " 68.0,\n",
       " 69.0,\n",
       " 70.0,\n",
       " 71.0,\n",
       " 72.0,\n",
       " 73.0,\n",
       " 74.0,\n",
       " 75.0,\n",
       " 76.0,\n",
       " 77.0,\n",
       " 78.0,\n",
       " 79.0,\n",
       " 80.0,\n",
       " 81.0,\n",
       " 82.0,\n",
       " 83.0,\n",
       " 84.0,\n",
       " 85.0,\n",
       " 86.0,\n",
       " 87.0,\n",
       " 88.0,\n",
       " 89.0,\n",
       " 90.0,\n",
       " 91.0,\n",
       " 92.0,\n",
       " 93.0,\n",
       " 94.0,\n",
       " 95.0,\n",
       " 96.0,\n",
       " 97.0,\n",
       " 98.0,\n",
       " 99.0,\n",
       " 100.0,\n",
       " 101.0,\n",
       " 102.0,\n",
       " 103.0,\n",
       " 104.0,\n",
       " 105.0,\n",
       " 106.0,\n",
       " 107.0,\n",
       " 108.0,\n",
       " 109.0,\n",
       " 110.0,\n",
       " 111.0,\n",
       " 112.0,\n",
       " 113.0,\n",
       " 114.0,\n",
       " 115.0,\n",
       " 116.0,\n",
       " 117.0,\n",
       " 118.0,\n",
       " 119.0,\n",
       " 120.0,\n",
       " 121.0,\n",
       " 122.0,\n",
       " 123.0,\n",
       " 124.0,\n",
       " 125.0,\n",
       " 126.0,\n",
       " 127.0,\n",
       " 128.0,\n",
       " 129.0,\n",
       " 130.0,\n",
       " 131.0,\n",
       " 132.0,\n",
       " 133.0,\n",
       " 134.0,\n",
       " 135.0,\n",
       " 136.0,\n",
       " 137.0,\n",
       " 138.0,\n",
       " 139.0,\n",
       " 140.0,\n",
       " 141.0,\n",
       " 142.0,\n",
       " 143.0,\n",
       " 144.0,\n",
       " 145.0,\n",
       " 146.0,\n",
       " 147.0,\n",
       " 148.0,\n",
       " 149.0,\n",
       " 150.0,\n",
       " 151.0,\n",
       " 152.0,\n",
       " 153.0,\n",
       " 154.0,\n",
       " 155.0,\n",
       " 156.0,\n",
       " 157.0,\n",
       " 158.0,\n",
       " 159.0,\n",
       " 160.0,\n",
       " 161.0,\n",
       " 162.0,\n",
       " 163.0,\n",
       " 164.0,\n",
       " 165.0,\n",
       " 166.0,\n",
       " 167.0,\n",
       " 168.0,\n",
       " 169.0,\n",
       " 170.0,\n",
       " 171.0,\n",
       " 172.0,\n",
       " 173.0,\n",
       " 174.0,\n",
       " 175.0,\n",
       " 176.0,\n",
       " 177.0,\n",
       " 178.0,\n",
       " 179.0,\n",
       " 180.0,\n",
       " 181.0,\n",
       " 182.0,\n",
       " 183.0,\n",
       " 184.0,\n",
       " 185.0,\n",
       " 186.0,\n",
       " 187.0,\n",
       " 188.0,\n",
       " 189.0,\n",
       " 190.0,\n",
       " 191.0,\n",
       " 192.0,\n",
       " 194.0,\n",
       " 195.0,\n",
       " 196.0,\n",
       " 197.0,\n",
       " 198.0,\n",
       " 199.0,\n",
       " 200.0,\n",
       " 201.0,\n",
       " 202.0,\n",
       " 203.0,\n",
       " 204.0,\n",
       " 205.0,\n",
       " 206.0,\n",
       " 207.0,\n",
       " 208.0,\n",
       " 209.0,\n",
       " 210.0,\n",
       " 211.0,\n",
       " 212.0,\n",
       " 213.0,\n",
       " 215.0,\n",
       " 216.0,\n",
       " 217.0,\n",
       " 218.0,\n",
       " 219.0,\n",
       " 220.0,\n",
       " 221.0,\n",
       " 222.0,\n",
       " 223.0,\n",
       " 224.0,\n",
       " 225.0,\n",
       " 226.0,\n",
       " 227.0,\n",
       " 228.0,\n",
       " 229.0,\n",
       " 230.0,\n",
       " 231.0,\n",
       " 232.0,\n",
       " 233.0,\n",
       " 234.0,\n",
       " 235.0,\n",
       " 236.0,\n",
       " 237.0,\n",
       " 238.0,\n",
       " 239.0,\n",
       " 240.0,\n",
       " 241.0,\n",
       " 242.0,\n",
       " 243.0,\n",
       " 244.0,\n",
       " 245.0,\n",
       " 246.0,\n",
       " 247.0,\n",
       " 248.0,\n",
       " 249.0,\n",
       " 250.0,\n",
       " 251.0,\n",
       " 252.0,\n",
       " 253.0,\n",
       " 254.0,\n",
       " 255.0,\n",
       " 256.0,\n",
       " 257.0,\n",
       " 258.0,\n",
       " 259.0,\n",
       " 260.0,\n",
       " 261.0,\n",
       " 262.0,\n",
       " 263.0,\n",
       " 264.0,\n",
       " 265.0,\n",
       " 266.0,\n",
       " 267.0,\n",
       " 268.0,\n",
       " 269.0,\n",
       " 271.0,\n",
       " 272.0,\n",
       " 273.0,\n",
       " 274.0,\n",
       " 275.0,\n",
       " 276.0,\n",
       " 277.0,\n",
       " 278.0,\n",
       " 279.0,\n",
       " 280.0,\n",
       " 281.0,\n",
       " 282.0,\n",
       " 283.0,\n",
       " 284.0,\n",
       " 285.0,\n",
       " 286.0,\n",
       " 287.0,\n",
       " 288.0,\n",
       " 289.0,\n",
       " 290.0,\n",
       " 291.0,\n",
       " 292.0,\n",
       " 293.0,\n",
       " 294.0,\n",
       " 295.0,\n",
       " 296.0,\n",
       " 297.0,\n",
       " 299.0,\n",
       " 300.0,\n",
       " 301.0,\n",
       " 302.0,\n",
       " 303.0,\n",
       " 304.0,\n",
       " 305.0,\n",
       " 306.0,\n",
       " 307.0,\n",
       " 308.0,\n",
       " 309.0,\n",
       " 310.0,\n",
       " 311.0,\n",
       " 312.0,\n",
       " 313.0,\n",
       " 314.0,\n",
       " 315.0,\n",
       " 316.0,\n",
       " 317.0,\n",
       " 318.0,\n",
       " 319.0,\n",
       " 320.0,\n",
       " 321.0,\n",
       " 322.0,\n",
       " 323.0,\n",
       " 324.0,\n",
       " 325.0,\n",
       " 326.0,\n",
       " 327.0,\n",
       " 328.0,\n",
       " 329.0,\n",
       " 330.0,\n",
       " 331.0,\n",
       " 332.0,\n",
       " 333.0,\n",
       " 334.0,\n",
       " 335.0,\n",
       " 336.0,\n",
       " 337.0,\n",
       " 338.0,\n",
       " 339.0,\n",
       " 340.0,\n",
       " 341.0,\n",
       " 342.0]"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used['C']['S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "6\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "5\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "6\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "7\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "5\n",
      "6\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "5\n",
      "2\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "6\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "6\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "3\n",
      "5\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "6\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "6\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "5\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for cabin in used['C']['S']:\n",
    "    print(len(df2[(df2.Side == 'S') & (df2.Deck == 'C') & (df.Number == cabin)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           B/0/P\n",
       "1           F/0/S\n",
       "2           A/0/S\n",
       "3           A/0/S\n",
       "4           F/1/S\n",
       "           ...   \n",
       "12965    G/1498/S\n",
       "12966    G/1499/S\n",
       "12967    G/1500/S\n",
       "12968     E/608/S\n",
       "12969     E/608/S\n",
       "Name: Cabin, Length: 12970, dtype: object"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                   0310_01\n",
       "HomePlanet                     Europa\n",
       "CryoSleep                       False\n",
       "Cabin                             NaN\n",
       "Destination               TRAPPIST-1e\n",
       "Age                              67.0\n",
       "VIP                             False\n",
       "RoomService                       NaN\n",
       "FoodCourt                       230.0\n",
       "ShoppingMall                      0.0\n",
       "Spa                            4476.0\n",
       "VRDeck                          241.0\n",
       "Name                 Naviton Coudered\n",
       "Set                             Train\n",
       "Transported                     False\n",
       "Group                             310\n",
       "GroupNumber                         1\n",
       "Deck                              NaN\n",
       "Number                            NaN\n",
       "Side                              NaN\n",
       "FirstName                     Naviton\n",
       "LastName                     Coudered\n",
       "GroupSize                           1\n",
       "Bills                             NaN\n",
       "potential_decks    [A, B, C, D, E, T]\n",
       "Name: 421, dtype: object"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[421]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "index 404\n",
      "passenger 0293_01\n",
      "GroupSize 1\n",
      "[['B', 'P', 12.0, 14.0], ['C', 'S', 12.0, 14.0]]\n",
      "\n",
      "index 421\n",
      "passenger 0310_01\n",
      "GroupSize 1\n",
      "[['B', 'P', 12.0, 14.0], ['C', 'S', 12.0, 14.0]]\n",
      "\n",
      "index 479\n",
      "passenger 0348_02\n",
      "GroupSize 2\n",
      "[['E', 'P', 19.0, 22.0]]\n",
      "\n",
      "index 505\n",
      "passenger 0364_02\n",
      "GroupSize 2\n",
      "[['E', 'P', 19.0, 22.0]]\n",
      "\n",
      "index 517\n",
      "passenger 0374_02\n",
      "GroupSize 2\n",
      "[['E', 'P', 19.0, 22.0]]\n",
      "\n",
      "index 1401\n",
      "passenger 0992_04\n",
      "GroupSize 6\n",
      "[['E', 'P', 57.0, 59.0]]\n",
      "\n",
      "index 1423\n",
      "passenger 1006_03\n",
      "GroupSize 3\n",
      "[['E', 'P', 57.0, 59.0]]\n",
      "\n",
      "index 1429\n",
      "passenger 1011_01\n",
      "GroupSize 2\n",
      "[['E', 'P', 57.0, 59.0]]\n",
      "\n",
      "index 1466\n",
      "passenger 1041_01\n",
      "GroupSize 1\n",
      "[['C', 'S', 39.0, 41.0], ['D', 'S', 35.0, 37.0], ['E', 'P', 57.0, 59.0]]\n",
      "\n",
      "index 1543\n",
      "passenger 1095_01\n",
      "GroupSize 1\n",
      "[['C', 'S', 39.0, 41.0], ['D', 'S', 35.0, 37.0]]\n",
      "\n",
      "index 2442\n",
      "passenger 1709_03\n",
      "GroupSize 7\n",
      "[]\n",
      "\n",
      "index 2970\n",
      "passenger 2092_03\n",
      "GroupSize 5\n",
      "[]\n",
      "\n",
      "index 3529\n",
      "passenger 2513_01\n",
      "GroupSize 1\n",
      "[['E', 'P', 149.0, 151.0], ['F', 'P', 518.0, 520.0]]\n",
      "\n",
      "index 3530\n",
      "passenger 2514_01\n",
      "GroupSize 1\n",
      "[['E', 'P', 149.0, 151.0], ['F', 'P', 518.0, 520.0]]\n",
      "\n",
      "index 4569\n",
      "passenger 3287_02\n",
      "GroupSize 3\n",
      "[]\n",
      "\n",
      "index 4577\n",
      "passenger 3292_02\n",
      "GroupSize 5\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 4751\n",
      "passenger 3411_02\n",
      "GroupSize 7\n",
      "[]\n",
      "\n",
      "index 4915\n",
      "passenger 3521_01\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 5016\n",
      "passenger 3598_01\n",
      "GroupSize 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['G', 'P', 589.0, 591.0], ['G', 'S', 578.0, 580.0]]\n",
      "\n",
      "index 5017\n",
      "passenger 3599_01\n",
      "GroupSize 1\n",
      "[['G', 'P', 589.0, 591.0], ['G', 'S', 578.0, 580.0]]\n",
      "\n",
      "index 5857\n",
      "passenger 4181_03\n",
      "GroupSize 6\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 6075\n",
      "passenger 4336_03\n",
      "GroupSize 4\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 6133\n",
      "passenger 4378_02\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 6472\n",
      "passenger 4625_03\n",
      "GroupSize 7\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 6535\n",
      "passenger 4662_03\n",
      "GroupSize 3\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 6578\n",
      "passenger 4690_02\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 6709\n",
      "passenger 4782_01\n",
      "GroupSize 5\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 6927\n",
      "passenger 4953_01\n",
      "GroupSize 1\n",
      "[['C', 'S', 192.0, 194.0], ['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 6952\n",
      "passenger 4974_02\n",
      "GroupSize 2\n",
      "[['C', 'S', 192.0, 194.0], ['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 7219\n",
      "passenger 5164_02\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 7333\n",
      "passenger 5254_03\n",
      "GroupSize 4\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 7638\n",
      "passenger 5480_01\n",
      "GroupSize 1\n",
      "[['C', 'S', 213.0, 215.0], ['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 7863\n",
      "passenger 5642_02\n",
      "GroupSize 2\n",
      "[['C', 'S', 213.0, 215.0], ['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 8102\n",
      "passenger 5815_01\n",
      "GroupSize 4\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 8413\n",
      "passenger 6028_04\n",
      "GroupSize 5\n",
      "[['D', 'P', 190.0, 192.0], ['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 8450\n",
      "passenger 6048_01\n",
      "GroupSize 1\n",
      "[['D', 'P', 190.0, 192.0], ['E', 'P', 386.0, 388.0]]\n",
      "\n",
      "index 8465\n",
      "passenger 6060_01\n",
      "GroupSize 1\n",
      "[['D', 'P', 190.0, 192.0], ['E', 'P', 386.0, 388.0]]\n",
      "\n",
      "index 8534\n",
      "passenger 6111_03\n",
      "GroupSize 5\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 8594\n",
      "passenger 6151_01\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 8822\n",
      "passenger 6312_01\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 8976\n",
      "passenger 6406_01\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 8994\n",
      "passenger 6421_02\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 9273\n",
      "passenger 6617_01\n",
      "GroupSize 3\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 9295\n",
      "passenger 6634_02\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan]]\n",
      "\n",
      "index 10081\n",
      "passenger 7182_01\n",
      "GroupSize 1\n",
      "[['F', 'P', 1488.0, 1490.0], ['G', 'P', 1156.0, 1158.0]]\n",
      "\n",
      "index 10082\n",
      "passenger 7183_01\n",
      "GroupSize 1\n",
      "[['F', 'P', 1488.0, 1490.0], ['G', 'P', 1156.0, 1158.0]]\n",
      "\n",
      "index 10127\n",
      "passenger 7219_04\n",
      "GroupSize 6\n",
      "[['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 10290\n",
      "passenger 7353_03\n",
      "GroupSize 3\n",
      "[['C', 'S', 269.0, 271.0], ['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 10313\n",
      "passenger 7368_01\n",
      "GroupSize 1\n",
      "[['C', 'S', 269.0, 271.0], ['D', 'P', 234.0, 236.0], ['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 10394\n",
      "passenger 7429_01\n",
      "GroupSize 1\n",
      "[['D', 'P', 234.0, 236.0], ['F', 'S', 1423.0, 1425.0]]\n",
      "\n",
      "index 10408\n",
      "passenger 7440_01\n",
      "GroupSize 1\n",
      "[['F', 'S', 1423.0, 1425.0], ['G', 'S', 1205.0, 1207.0]]\n",
      "\n",
      "index 10411\n",
      "passenger 7442_02\n",
      "GroupSize 2\n",
      "[['F', 'S', 1423.0, 1425.0], ['G', 'S', 1205.0, 1207.0]]\n",
      "\n",
      "index 10434\n",
      "passenger 7463_01\n",
      "GroupSize 1\n",
      "[['F', 'P', 1543.0, 1545.0], ['F', 'S', 1423.0, 1425.0], ['G', 'S', 1211.0, 1213.0]]\n",
      "\n",
      "index 10440\n",
      "passenger 7469_01\n",
      "GroupSize 1\n",
      "[['F', 'P', 1543.0, 1545.0], ['G', 'S', 1211.0, 1213.0]]\n",
      "\n",
      "index 10558\n",
      "passenger 7556_03\n",
      "GroupSize 4\n",
      "[['D', 'P', 234.0, 236.0], ['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 10855\n",
      "passenger 7787_02\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 11074\n",
      "passenger 7942_02\n",
      "GroupSize 2\n",
      "[['G', 'P', 1285.0, 1287.0], ['G', 'S', 1281.0, 1283.0]]\n",
      "\n",
      "index 11082\n",
      "passenger 7948_01\n",
      "GroupSize 1\n",
      "[['G', 'P', 1285.0, 1287.0], ['G', 'S', 1281.0, 1283.0]]\n",
      "\n",
      "index 11129\n",
      "passenger 7983_01\n",
      "GroupSize 1\n",
      "[['C', 'S', 297.0, 299.0], ['E', 'S', 527.0, 529.0], ['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 11148\n",
      "passenger 7995_01\n",
      "GroupSize 1\n",
      "[['C', 'S', 297.0, 299.0], ['E', 'S', 527.0, 529.0], ['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 11598\n",
      "passenger 8322_01\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 11999\n",
      "passenger 8605_02\n",
      "GroupSize 5\n",
      "[['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 12174\n",
      "passenger 8728_07\n",
      "GroupSize 8\n",
      "[]\n",
      "\n",
      "index 12241\n",
      "passenger 8772_02\n",
      "GroupSize 2\n",
      "[['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 12651\n",
      "passenger 9057_01\n",
      "GroupSize 2\n",
      "[['A', 'P', 93.0, 95.0], ['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 12658\n",
      "passenger 9062_02\n",
      "GroupSize 2\n",
      "[['G', 'P', 1473.0, 1475.0]]\n",
      "\n",
      "index 12668\n",
      "passenger 9069_03\n",
      "GroupSize 5\n",
      "[['A', 'P', 93.0, 95.0], ['T', 'P', 4.0, nan], ['T', 'S', 3.0, nan]]\n",
      "\n",
      "index 12671\n",
      "passenger 9070_01\n",
      "GroupSize 2\n",
      "[['G', 'P', 1473.0, 1475.0]]\n"
     ]
    }
   ],
   "source": [
    "remaining_cabins(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deck a needs one deck b needs 3 all p d needs 3 p\n",
    "deck c needs 6 s\n",
    "deck e needs 5 p and 2 s\n",
    "deck f needs 4 p and 2 s\n",
    "deck g needs 4 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deck B side P number 13\n",
      "404    0293_01\n",
      "421    0310_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck F side P number 519\n",
      "3529    2513_01\n",
      "3530    2514_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck F side P number 1489\n",
      "10081    7182_01\n",
      "10082    7183_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck F side P number 1544\n",
      "10434    7463_01\n",
      "10440    7469_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck F side S number 1424\n",
      "10394    7429_01\n",
      "10408    7440_01\n",
      "10411    7442_02\n",
      "10434    7463_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck A side P number 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12651    9057_01\n",
      "12668    9069_03\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck G side P number 590\n",
      "5016    3598_01\n",
      "5017    3599_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck G side P number 1157\n",
      "10081    7182_01\n",
      "10082    7183_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck G side P number 1286\n",
      "11074    7942_02\n",
      "11082    7948_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck G side P number 1474\n",
      "12658    9062_02\n",
      "12671    9070_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck G side S number 579\n",
      "5016    3598_01\n",
      "5017    3599_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck G side S number 1206\n",
      "10408    7440_01\n",
      "10411    7442_02\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck G side S number 1212\n",
      "10434    7463_01\n",
      "10440    7469_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck G side S number 1282\n",
      "11074    7942_02\n",
      "11082    7948_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck C side S number 13\n",
      "404    0293_01\n",
      "421    0310_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck C side S number 40\n",
      "1466    1041_01\n",
      "1543    1095_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck C side S number 193\n",
      "6927    4953_01\n",
      "6952    4974_02\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck C side S number 214\n",
      "7638    5480_01\n",
      "7863    5642_02\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck C side S number 270\n",
      "10290    7353_03\n",
      "10313    7368_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck C side S number 298\n",
      "11129    7983_01\n",
      "11148    7995_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck E side P number 20\n",
      "479    0348_02\n",
      "505    0364_02\n",
      "517    0374_02\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck E side P number 21\n",
      "479    0348_02\n",
      "505    0364_02\n",
      "517    0374_02\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck E side P number 58\n",
      "1401    0992_04\n",
      "1423    1006_03\n",
      "1429    1011_01\n",
      "1466    1041_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck E side P number 150\n",
      "3529    2513_01\n",
      "3530    2514_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck E side P number 387\n",
      "8450    6048_01\n",
      "8465    6060_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck E side S number 528\n",
      "11129    7983_01\n",
      "11148    7995_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck D side P number 191\n",
      "8413    6028_04\n",
      "8450    6048_01\n",
      "8465    6060_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck D side P number 235\n",
      "10313    7368_01\n",
      "10394    7429_01\n",
      "10558    7556_03\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "deck D side S number 36\n",
      "1466    1041_01\n",
      "1543    1095_01\n",
      "Name: PassengerId, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fill_by_empty_room(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spaceenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
